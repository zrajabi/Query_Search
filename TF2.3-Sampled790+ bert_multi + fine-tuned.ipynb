{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8l4RJ0XRPEm",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Embedding, Dropout, Activation,  Conv1D\n",
    "from tensorflow.keras.layers import GRU,LSTM, Bidirectional, GlobalAveragePooling2D, GlobalMaxPool1D, GlobalAveragePooling2D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "#from keras.layers import TimeDistributed\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "\n",
    "# text processing\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "\n",
    "############## parameters\n",
    "#sampling\n",
    "n_samples = 790\n",
    "load_samples = False\n",
    "\n",
    "# image model\n",
    "IMG_SHAPE = (240, 240, 3)  # All images will be resized to 160x160 to match our image dataset\n",
    "IMG_SIZE = 240\n",
    "\n",
    "\n",
    "# word embeddings\n",
    "MAX_NB_WORDS = 120000 # max number of words in dictionary\n",
    "MAX_SENT_LENGTH = 20 # max number of words in a sentence (short text)\n",
    "MAX_SENTS = 10 # max number of sentences in a query text\n",
    "EMBEDDING_DIM = 512 ## the dimension of text embedding \n",
    "\n",
    "## Training deep learning model\n",
    "NB_EPOCHS = 10\n",
    "BATCH_SIZE = 1 # increased from 16\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "## triplet loss learning\n",
    "SHARED_EMBEDDING_DIM = 768\n",
    "EMBEDDING_DIM = 512 ## the dimension of GloVe text embedding \n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bert-for-tf2\n",
    "#!pip install bert-tensorflow\n",
    "import bert\n",
    "from bert import tokenization\n",
    "from bert import bert_tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q tf-models-official==2.3\n",
    "#! pip install --upgrade tensorflow-hub\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.config.set_visible_devices(physical_devices[3], 'GPU')\n",
    "    #tf.config.experimental.set_memory_growth([physical_devices[0],physical_devices[1]], True)\n",
    "    logical_devices = tf.config.list_logical_devices('GPU')\n",
    "    assert len(logical_devices) == len(physical_devices) - 1\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(physical_devices), \"Physical GPUs,\", len(logical_devices), \"Logical GPU\")\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pre-processed Saved Data Sample objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = ['query','country','positive_cid','negative_cid','position_bias']\n",
    "cid_title_names = ['content_id','title']\n",
    "new_dir = \"/data/src/train_{}/\".format(n_samples)\n",
    "\n",
    "\n",
    "PROJECT_DIR = '/data/'\n",
    "DATASET_DIR = '/data/datasets/'\n",
    "SRC_DIR = PROJECT_DIR + 'src/'\n",
    "OBJECTS_DIR = PROJECT_DIR + 'objects/'\n",
    "\n",
    "joined_temp_path = DATASET_DIR \n",
    "all_images_path = PROJECT_DIR+ 'images/'\n",
    "\n",
    "training_data_path = DATASET_DIR + 'training_data/'\n",
    "embedding_data_file = '/data/embeddings/glove.6B.100d.txt'\n",
    "OBJECTS_DIR = new_dir + 'objects/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790 790 790 790 790 790\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampled_train = pd.read_pickle(OBJECTS_DIR + 'cleaned_all_english_sampled_train{}.pkl'.format(n_samples))\n",
    "n_samples = len(sampled_train)\n",
    "\n",
    "with open(OBJECTS_DIR +  'cleaned_all_english_n_img_paths{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    n_img_paths = pickle.load(f)\n",
    "\n",
    "with open(OBJECTS_DIR +  'cleaned_all_english_p_img_paths{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    p_img_paths = pickle.load(f)\n",
    "\n",
    "with open(OBJECTS_DIR + 'cleaned_all_english_position_bias{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    position_bias = pickle.load(f)\n",
    "    \n",
    "query_seqs = sample_queries = sampled_train['query'].to_list()\n",
    "print(len(p_img_paths),len(query_seqs),len(n_img_paths),len(sampled_train),len(position_bias), len(sample_queries))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Multilingual Bert models:\n",
    "1- Bidirectional Encoder Representations from Transformers (BERT): \n",
    "    bert_multi_cased_L-12_H-768_A-12 \n",
    "    https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\n",
    "    \n",
    "2- Language-agnostic BERT sentence embedding model supporting 109 languages:\n",
    "    https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html?m=1\n",
    "    https://tfhub.dev/google/LaBSE/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Text Model : Language-Agnostic BERT Sentence Embedding  \n",
    "LaBSE_model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 40  # Your choice here.\n",
    "LaBSE = 1\n",
    "classification = 0\n",
    "\n",
    "### LABSE\n",
    "bert_multi_model_url = \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\"\n",
    "LaBSE_model_url = \"https://tfhub.dev/google/LaBSE/1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 40) (None, 40) (None, 40)\n",
      "(None, 768) (None, 40, 768)\n"
     ]
    }
   ],
   "source": [
    "def get_bert_model(model_url, max_seq_length):\n",
    "    # Define input.\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                         name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                     name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                      name=\"segment_ids\")\n",
    "    print(input_word_ids.shape, input_mask.shape, segment_ids.shape)\n",
    "\n",
    "    bert_layer = hub.KerasLayer(model_url,trainable=True)\n",
    "    \n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    \n",
    "    if LaBSE == 1:\n",
    "        # The embedding is l2 normalized.\n",
    "        pooled_output = tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(pooled_output)\n",
    "\n",
    "    #### adding more layers in case of classification:\n",
    "    if classification == 1:\n",
    "        cls_out = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(sequence_output)\n",
    "        cls_out = tf.keras.layers.Dropout(0.5)(cls_out)\n",
    "        #logits = tf.keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
    "        #logits = tf.keras.layers.Dropout(0.5)(logits)\n",
    "        logits = tf.keras.layers.Dense(units=2, activation=\"softmax\")(logits)\n",
    "\n",
    "        #return tf.keras.Model(inputs=input_ids, outputs=logits)\n",
    "    #### \n",
    "    \n",
    "    print(pooled_output.shape, sequence_output.shape)\n",
    "\n",
    "    return tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], \n",
    "                          outputs = [pooled_output, sequence_output]), bert_layer, pooled_output, sequence_output\n",
    "\n",
    "bert_text_model, bert_layer , pooled_output, sequence_output = get_bert_model(LaBSE_model_url,  max_seq_length = max_seq_length)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output (None, 768)\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      [(None, 768), (None, 470926849   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           keras_layer_1[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 768)          590592      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 471,517,441\n",
      "Trainable params: 471,517,440\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def multi_labse_bert_model(model_url, max_seq_length):\n",
    "    '''\n",
    "    input = 3*tokenized text\n",
    "    output = logits\n",
    "    '''\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                         name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                     name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                      name=\"segment_ids\")\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(model_url,trainable=True)\n",
    "    \n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, \n",
    "                                                 input_mask, \n",
    "                                                 segment_ids])\n",
    "\n",
    "    cls_out = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(sequence_output) # get the CLS token\n",
    "    #cls_out = tf.keras.layers.Dropout(0.5)(cls_out)\n",
    "    #logits = tf.keras.layers.Dense(SHARED_EMBEDDING_DIM,  activation = 'tanh')(cls_out)\n",
    "    output = tf.keras.layers.Dropout(0.5)(cls_out)\n",
    "    logits = tf.keras.layers.Dense(SHARED_EMBEDDING_DIM, \n",
    "                                   activation = None)(cls_out)\n",
    "    output = tf.keras.layers.Dropout(0.3)(logits)\n",
    "    print('output',output.shape )\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_word_ids, input_mask,  segment_ids], outputs = output)\n",
    "    \n",
    "    model.summary()\n",
    "    return model, bert_layer , pooled_output, sequence_output\n",
    "\n",
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    text_model, bert_layer , pooled_output, sequence_output = multi_labse_bert_model(LaBSE_model_url, max_seq_length = max_seq_length)\n",
    "#messages = sampled_train.iloc[0:10]['query'].apply(lambda x: eval(x)).values.tolist()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaBSE bert Tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 501103\n",
      "['Hello', 'Tens', '##or', '##Flow', '!']\n",
      "[34637, 340137, 16154, 418550, 106]\n"
     ]
    }
   ],
   "source": [
    "import bert\n",
    "from bert import tokenization\n",
    "from bert import bert_tokenization\n",
    "\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "print(\"Vocab size:\", len(tokenizer.vocab))\n",
    "\n",
    "tokens = tokenizer.tokenize(\"Hello TensorFlow!\")\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sentences for Bert\n",
    "The model expects its two inputs sentences to be concatenated together. This input is expected to start with a `[CLS]` \"This is a classification problem\" token, and each sentence should end with a `[SEP]` \"Separator\" token:\n",
    "\n",
    "We prepare/encode the data for feeding into our BERT model by:\n",
    "\n",
    "    1- tokenizing the text\n",
    "    2- trim or pad it to a max_seq_len length\n",
    "    3- append the special tokens [CLS] and [SEP]\n",
    "    4- convert the string tokens to numerical IDs using the original model's token encoding from vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(input_strings, tokenizer, max_seq_length):\n",
    "\n",
    "    input_ids_all, input_mask_all, segment_ids_all = [], [], []\n",
    "    for input_string in input_strings:\n",
    "        # Tokenize input.\n",
    "        input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "        sequence_length = min(len(input_ids), max_seq_length)\n",
    "\n",
    "        # Padding or truncation.\n",
    "        if len(input_ids) >= max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "        else:\n",
    "            input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n",
    "\n",
    "        input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n",
    "\n",
    "        input_ids_all.append(input_ids)\n",
    "        input_mask_all.append(input_mask)\n",
    "        segment_ids_all.append([0] * max_seq_length)\n",
    "\n",
    "    return np.array(input_ids_all), np.array(input_mask_all), np.array(segment_ids_all)\n",
    "\n",
    "\n",
    "def bert_encode(input_text, text_model):\n",
    "    '''\n",
    "    input : text\n",
    "    output: bert embeddings\n",
    "    '''\n",
    "    \n",
    "    input_ids, input_mask, segment_ids = create_input(input_text, tokenizer, max_seq_length)\n",
    "    #inputs = [input_ids, input_mask, segment_ids]\n",
    "    #print(len(inputs))\n",
    "    return tf.convert_to_tensor(input_ids,dtype= tf.int32), tf.convert_to_tensor(input_mask,dtype= tf.int32), tf.convert_to_tensor(segment_ids,dtype= tf.int32) #text_model(inputs)\n",
    "\n",
    "#multi_bert_embeddings = bert_encode(sampled_train['query'].apply(lambda x: eval(x)), text_model)\n",
    "#len(multi_bert_embeddings), multi_bert_embeddings[0].shape,  multi_bert_embeddings[1].shape\n",
    "# print(sampled_train.iloc[0:1]['query'].apply(lambda x: eval(x)))\n",
    "# be = bert_encode(sampled_train.iloc[0:1]['query'].apply(lambda x: eval(x)), text_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Encoder Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- InceptionV3   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_inceptionv3_model(IMG_SHAPE, SHARED_EMBEDDING_DIM):\n",
    "    base_model = tf.keras.applications.InceptionV3(input_shape = IMG_SHAPE,\n",
    "                                                   include_top = False,\n",
    "                                                   weights = 'imagenet')# By specifying the include_top=False argument, you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction.\n",
    "    x = base_model.output  #x = image_model.layers[-1].output #--> which one is correct?\n",
    "    x = GlobalAveragePooling2D()(x)  \n",
    "    x = Dense(SHARED_EMBEDDING_DIM, activation= None )(x) # is it correct to match the word embeddings?\n",
    "    y = Dropout(0.3)(x)\n",
    "    #y = tf.math.l2_normalize(x, axis=1)\n",
    "    image_model = tf.keras.Model(inputs = base_model.input, outputs = y)\n",
    "    image_model.summary()\n",
    "\n",
    "    return image_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240, 240, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 119, 119, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 119, 119, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 119, 119, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 117, 117, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 117, 117, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 117, 117, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 117, 117, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 117, 117, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 117, 117, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 58, 58, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 58, 58, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 58, 58, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 58, 58, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 27, 27, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 27, 27, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 27, 27, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 27, 27, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 27, 27, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 27, 27, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 27, 27, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 27, 27, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 27, 27, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 27, 27, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 27, 27, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 27, 27, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 27, 27, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 27, 27, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 27, 27, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 27, 27, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 27, 27, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 27, 27, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 27, 27, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 27, 27, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 27, 27, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 27, 27, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 27, 27, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 27, 27, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 27, 27, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 27, 27, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 27, 27, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 27, 27, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 27, 27, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 27, 27, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 27, 27, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 27, 27, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 27, 27, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 27, 27, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 27, 27, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 27, 27, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 27, 27, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 27, 27, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 27, 27, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 27, 27, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 27, 27, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 27, 27, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 27, 27, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 27, 27, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 27, 27, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 27, 27, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 27, 27, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 27, 27, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 27, 27, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 27, 27, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 27, 27, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 27, 27, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 27, 27, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 27, 27, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 27, 27, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 27, 27, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 27, 27, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 27, 27, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 27, 27, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 27, 27, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 27, 27, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 27, 27, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 27, 27, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 27, 27, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 27, 27, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 27, 27, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 27, 27, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 27, 27, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 27, 27, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 27, 27, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 27, 27, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 27, 27, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 27, 27, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 27, 27, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 27, 27, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 13, 13, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 13, 13, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 13, 13, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 13, 13, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 13, 13, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 13, 13, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 13, 13, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 13, 13, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 13, 13, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 13, 13, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 13, 13, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 13, 13, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 13, 13, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 13, 13, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 13, 13, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 13, 13, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 13, 13, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 13, 13, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 13, 13, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 13, 13, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 13, 13, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 13, 13, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 13, 13, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 13, 13, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 13, 13, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 13, 13, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 13, 13, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 13, 13, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 13, 13, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 13, 13, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 13, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 13, 13, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 13, 13, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 13, 13, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 13, 13, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 13, 13, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 13, 13, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 13, 13, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 13, 13, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 13, 13, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 13, 13, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 13, 13, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 13, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 13, 13, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 13, 13, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 13, 13, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 13, 13, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 13, 13, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 13, 13, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 13, 13, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 13, 13, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 13, 13, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 13, 13, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 13, 13, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 13, 13, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 13, 13, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 13, 13, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 13, 13, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 13, 13, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 13, 13, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 13, 13, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 13, 13, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 13, 13, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 13, 13, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 13, 13, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 13, 13, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 13, 13, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 13, 13, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 13, 13, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 13, 13, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 13, 13, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 13, 13, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 13, 13, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 13, 13, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 13, 13, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 13, 13, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 13, 13, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 13, 13, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 13, 13, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 13, 13, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 13, 13, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 13, 13, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 13, 13, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 13, 13, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 13, 13, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 13, 13, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 13, 13, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 13, 13, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 13, 13, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 13, 13, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 13, 13, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 13, 13, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 13, 13, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 13, 13, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 13, 13, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 13, 13, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 13, 13, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 13, 13, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 13, 13, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 13, 13, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 13, 13, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 13, 13, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 13, 13, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 13, 13, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 13, 13, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 13, 13, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 13, 13, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 13, 13, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 13, 13, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 13, 13, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 13, 13, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 13, 13, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 13, 13, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 13, 13, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 13, 13, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 13, 13, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 13, 13, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 13, 13, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 13, 13, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 13, 13, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 13, 13, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 13, 13, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 13, 13, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 13, 13, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 13, 13, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 13, 13, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 13, 13, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 13, 13, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 13, 13, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 13, 13, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 13, 13, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 13, 13, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 13, 13, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 13, 13, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 13, 13, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 13, 13, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 13, 13, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 13, 13, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 13, 13, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 13, 13, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 13, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 13, 13, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 13, 13, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 13, 13, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 13, 13, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 13, 13, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 13, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 768)          1573632     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,376,416\n",
      "Trainable params: 23,341,984\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    image_model = image_inceptionv3_model(IMG_SHAPE, SHARED_EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f674c1f1160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 512, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length, EMBEDDING_DIM, SHARED_EMBEDDING_DIM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Ranking Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_distance(encodings, position_bias_batch_wise, margin = 1): \n",
    "    encoded_anchor, encoded_positive, encoded_negative = encodings\n",
    "    pos_dot = tf.linalg.diag_part(tf.tensordot(encoded_anchor, tf.transpose(encoded_positive),1))\n",
    "    neg_dot = tf.linalg.diag_part(tf.tensordot(encoded_anchor, tf.transpose(encoded_negative),1))\n",
    "    sq_pos_dist = tf.math.sqrt(tf.math.square(tf.norm(encoded_anchor,axis= 1 )) + tf.math.square(tf.norm(encoded_positive,axis= 1 )) - 2*pos_dot)\n",
    "    sq_neg_dist = tf.math.sqrt(tf.math.square(tf.norm(encoded_anchor, axis= 1 )) + tf.math.square(tf.norm(encoded_negative,axis= 1 )) - 2*neg_dot)\n",
    "    basic_loss = sq_pos_dist - sq_neg_dist + margin \n",
    "    basic_loss = tf.expand_dims( tf.math.maximum(0.0 , basic_loss),0) #HERE, you should add batch_wise COST\n",
    "    basic_loss = tf.math.multiply(basic_loss, position_bias_batch_wise)# element-wise multiplication\n",
    "    loss = tf.reduce_sum(basic_loss, axis = 1) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. string - [128,128, 128] - inputs=[input_word_ids, input_mask,  segment_ids], outputs = output)\n",
    "def get_model(IMG_SHAPE, BATCH_SIZE, MAX_SENT_LENGTH, image_model, text_model, margin = 1):\n",
    "    positive_input = Input(shape = IMG_SHAPE,\n",
    "                           name='positive_image_input')\n",
    "    negative_input = Input(shape = IMG_SHAPE,\n",
    "                           name='negative_image_input')\n",
    "    encoded_positive = image_model(positive_input)\n",
    "    encoded_negative = image_model(negative_input) \n",
    "    \n",
    "    position_bias_input = Input(shape = (), name = 'cost') \n",
    "    \n",
    "    # instead of previous anchor input, we should use 3 inputs for bert\n",
    "    #anchor_input = Input(shape=(EMBEDDING_DIM,), dtype=tf.int32, name='anchor_query_input')\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    encoded_anchor = text_model([input_word_ids, input_mask,  segment_ids])\n",
    "    \n",
    "    inputs = [input_word_ids, input_mask, segment_ids, positive_input, negative_input, position_bias_input]\n",
    "    \n",
    "    outputs = [encoded_anchor, encoded_positive, encoded_negative] # 100D both image and text embeddings\n",
    "    \n",
    "    triplet_model = Model(inputs = inputs, outputs = outputs) \n",
    "    triplet_model.add_loss(triplet_loss_distance(outputs,position_bias_input, margin))\n",
    "    triplet_model.summary()\n",
    "    \n",
    "    return triplet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_image_input (InputLaye [(None, 240, 240, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_image_input (InputLaye [(None, 240, 240, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cost (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 768)          471517441   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "functional_5 (Functional)       (None, 768)          23376416    positive_image_input[0][0]       \n",
      "                                                                 negative_image_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(768, None)]        0           functional_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_3 (Tensor [(768, None)]        0           functional_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(2,)]               0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(2,)]               0           tf_op_layer_Transpose_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2 (TensorFlo [(1,)]               0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_1 (TensorF [(1,)]               0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_3 (TensorF [(1,)]               0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_2 (TensorF [(1,)]               0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_4 (TensorF [(1,)]               0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_5 (TensorF [(1,)]               0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_7 (TensorF [(1,)]               0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_6 (TensorF [(1,)]               0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod (TensorFlowOpL [()]                 0           tf_op_layer_GatherV2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_1 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_3 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_2 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_4 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_5 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_7 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Prod_6 (TensorFlowO [()]                 0           tf_op_layer_GatherV2_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 768)]        0           functional_3[0][0]               \n",
      "                                                                 functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 768)]        0           functional_5[0][0]               \n",
      "                                                                 functional_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_1 (Tensor [(None, 768)]        0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(2,)]               0           tf_op_layer_Prod[0][0]           \n",
      "                                                                 tf_op_layer_Prod_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_2 (Tensor [(768, None)]        0           tf_op_layer_Transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_1 (TensorFlow [(2,)]               0           tf_op_layer_Prod_3[0][0]         \n",
      "                                                                 tf_op_layer_Prod_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 768)]        0           functional_3[0][0]               \n",
      "                                                                 functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 768)]        0           functional_5[1][0]               \n",
      "                                                                 functional_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_4 (Tensor [(None, 768)]        0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_2 (TensorFlow [(2,)]               0           tf_op_layer_Prod_4[0][0]         \n",
      "                                                                 tf_op_layer_Prod_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_5 (Tensor [(768, None)]        0           tf_op_layer_Transpose_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_3 (TensorFlow [(2,)]               0           tf_op_layer_Prod_7[0][0]         \n",
      "                                                                 tf_op_layer_Prod_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 1)]          0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, None)]       0           tf_op_layer_Transpose_1[0][0]    \n",
      "                                                                 tf_op_layer_stack[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, None)]       0           tf_op_layer_Transpose_2[0][0]    \n",
      "                                                                 tf_op_layer_stack_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 1)]          0           tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(None, 1)]          0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, None)]       0           tf_op_layer_Transpose_4[0][0]    \n",
      "                                                                 tf_op_layer_stack_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, None)]       0           tf_op_layer_Transpose_5[0][0]    \n",
      "                                                                 tf_op_layer_stack_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt (TensorFlowOpL [(None, 1)]          0           tf_op_layer_Sum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_1 (TensorFlowO [(None, 1)]          0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul (TensorFlowO [(None, None)]       0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(2,)]               0           tf_op_layer_GatherV2[0][0]       \n",
      "                                                                 tf_op_layer_GatherV2_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_3 (TensorFlowO [(None, 1)]          0           tf_op_layer_Sum_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_4 (TensorFlowO [(None, 1)]          0           tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul_1 (TensorFlo [(None, None)]       0           tf_op_layer_Reshape_3[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(2,)]               0           tf_op_layer_GatherV2_4[0][0]     \n",
      "                                                                 tf_op_layer_GatherV2_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None,)]            0           tf_op_layer_Sqrt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None,)]            0           tf_op_layer_Sqrt_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, None)]       0           tf_op_layer_MatMul[0][0]         \n",
      "                                                                 tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None,)]            0           tf_op_layer_Sqrt_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_3 (TensorFl [(None,)]            0           tf_op_layer_Sqrt_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, None)]       0           tf_op_layer_MatMul_1[0][0]       \n",
      "                                                                 tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None,)]            0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_1 (TensorFlo [(None,)]            0           tf_op_layer_Squeeze_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag_part (TensorFl [(None,)]            0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_2 (TensorFlo [(None,)]            0           tf_op_layer_Squeeze_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_3 (TensorFlo [(None,)]            0           tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag_part_1 (Tensor [(None,)]            0           tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None,)]            0           tf_op_layer_Square[0][0]         \n",
      "                                                                 tf_op_layer_Square_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(None,)]            0           tf_op_layer_diag_part[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None,)]            0           tf_op_layer_Square_2[0][0]       \n",
      "                                                                 tf_op_layer_Square_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None,)]            0           tf_op_layer_diag_part_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None,)]            0           tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_Mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None,)]            0           tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_Mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_2 (TensorFlowO [(None,)]            0           tf_op_layer_Sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_5 (TensorFlowO [(None,)]            0           tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_2 (TensorFlowOp [(None,)]            0           tf_op_layer_Sqrt_2[0][0]         \n",
      "                                                                 tf_op_layer_Sqrt_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None,)]            0           tf_op_layer_Sub_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Maximum (TensorFlow [(None,)]            0           tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(1, None)]          0           tf_op_layer_Maximum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [(1, None)]          0           tf_op_layer_ExpandDims[0][0]     \n",
      "                                                                 cost[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_4 (TensorFlowOp [(1,)]               0           tf_op_layer_Mul_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              (1,)                 0           tf_op_layer_Sum_4[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 494,893,857\n",
      "Trainable params: 494,859,424\n",
      "Non-trainable params: 34,433\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5d276a826984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtriplet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SENT_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mimage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     triplet_model.compile(optimizer = optimizer,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    #triplet_model = get_model_normalized_input(IMG_SHAPE, BATCH_SIZE, MAX_SENT_LENGTH, image_model, text_model, margin= 0.1)\n",
    "    triplet_model = get_model(IMG_SHAPE, BATCH_SIZE, MAX_SENT_LENGTH,  image_model, text_model, margin= 1)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    triplet_model.compile(optimizer = optimizer,\n",
    "                loss = triplet_loss_distance)\n",
    "triplet_model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.run_eagerly = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test size: 158 \n",
      "train size: 422 \n",
      "validation size: 210\n"
     ]
    }
   ],
   "source": [
    "path = '/data/src/train_{}/objects/'.format(n_samples)  # new_dir + 'train_7120759/'\n",
    "path = os.path.join(path)\n",
    "with open(path+ 'list_IDs{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs = pickle.load(f) \n",
    "with open(path+ 'list_IDs_test{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs_test = pickle.load(f) \n",
    "with open(path+ 'list_IDs_val{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs_val = pickle.load(f) \n",
    "with open(path+ 'list_IDs_train{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs_train = pickle.load(f)\n",
    "\n",
    "print('\\ntest size:',len(list_IDs_test), \n",
    "      '\\ntrain size:', len(list_IDs_train), \n",
    "      '\\nvalidation size:', len(list_IDs_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_gen_series(x):\n",
    "    for i in range(len(x)):\n",
    "        yield eval(x[i])\n",
    "        \n",
    "\n",
    "#@tf.function\n",
    "def simple_load_image(path):\n",
    "    img1 = tf.io.read_file(path)\n",
    "    img1 = tf.image.decode_jpeg(img1, channels=3)\n",
    "    img1 = tf.image.resize(img1, (240, 240))\n",
    "    #img_tensor = tf.keras.applications.inception_v3.preprocess_input(img1)\n",
    "    #print(type(img_tensor)) #<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "    return img1\n",
    "\n",
    "#@tf.function\n",
    "def load_image(path):\n",
    "    img1 = tf.io.read_file(path)\n",
    "    img1 = tf.image.decode_jpeg(img1, channels=3)\n",
    "    img1 = tf.image.resize(img1, (240, 240))\n",
    "    img_tensor = tf.keras.applications.inception_v3.preprocess_input(img1) # Preprocess the images using the preprocess_input method to normalize the image so that it contains pixels in the range of -1 to 1, \n",
    "    #which matches the format of the images used to train InceptionV3.\n",
    "    print(type(img_tensor)) #<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "    return img_tensor\n",
    "\n",
    "#@tf.function\n",
    "def img_gen_series(x):\n",
    "    for i in range(len(x)):\n",
    "        yield tf.numpy_function(load_image(x[i]))\n",
    "#@tf.function\n",
    "def gen_series(x):\n",
    "    for i in range(len(x)):\n",
    "        yield x[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset for Training the Triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 158 210\n"
     ]
    }
   ],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    from operator import itemgetter  ## returns tuple, be careful\n",
    "\n",
    "    train_query_seqs = itemgetter(*list_IDs_train)(query_seqs)\n",
    "    train_position_bias = itemgetter(*list_IDs_train)(position_bias)\n",
    "    train_p_img_paths = itemgetter(*list_IDs_train)(p_img_paths)\n",
    "    train_n_img_paths = itemgetter(*list_IDs_train)(n_img_paths)\n",
    "\n",
    "    test_query_seqs = itemgetter(*list_IDs_test)(query_seqs)\n",
    "    test_position_bias = itemgetter(*list_IDs_test)(position_bias)\n",
    "    test_p_img_paths = itemgetter(*list_IDs_test)(p_img_paths)\n",
    "    test_n_img_paths = itemgetter(*list_IDs_test)(n_img_paths)\n",
    "\n",
    "    val_query_seqs = itemgetter(*list_IDs_val)(query_seqs)\n",
    "    val_position_bias = itemgetter(*list_IDs_val)(position_bias)\n",
    "    val_p_img_paths = itemgetter(*list_IDs_val)(p_img_paths)\n",
    "    val_n_img_paths = itemgetter(*list_IDs_val)(n_img_paths)\n",
    "\n",
    "    print(len(train_position_bias), len(test_p_img_paths), len(val_n_img_paths))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_query_dataset = tf.data.Dataset.from_generator(lambda: text_gen_series(train_query_seqs), \n",
    "                                                          output_types=(tf.string), \n",
    "                                                          output_shapes=( ( )))\n",
    "\n",
    "test_query_dataset = tf.data.Dataset.from_generator(lambda: text_gen_series(test_query_seqs), \n",
    "                                                          output_types=(tf.string), \n",
    "                                                          output_shapes=( ( )))\n",
    "    \n",
    "val_query_dataset = tf.data.Dataset.from_generator(lambda: text_gen_series(val_query_seqs), \n",
    "                                                          output_types=(tf.string), \n",
    "                                                          output_shapes=( ( )))\n",
    "train_query_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# position_bias_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index = 0)):\n",
    "    train_position_bias_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_series(train_position_bias), \n",
    "        output_types=(tf.float32), \n",
    "        output_shapes = ( ())) # if set it (1,) -> ValueError: `generator` yielded an element of shape () where an element of shape (1,) was expected\n",
    "\n",
    "    test_position_bias_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_series(test_position_bias), \n",
    "        output_types=(tf.float32), \n",
    "        output_shapes = ( ())) # if set it (1,) -> ValueError: `generator` yielded an element of shape () where an element of shape (1,) was expected\n",
    "\n",
    "    val_position_bias_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_series(val_position_bias), \n",
    "        output_types=(tf.float32), \n",
    "        output_shapes = ( ())) # if set it (1,) -> ValueError: `generator` yielded an element of shape () where an element of shape (1,) was expected\n",
    "\n",
    "    train_position_bias_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pos_img_dataset ,  neg_img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: (240, 240, 3), types: tf.float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########  RUN THIS for image dataset********************* from_tensor_slices works\n",
    "train_pos_img_dataset = tf.data.Dataset.from_tensor_slices(list(train_p_img_paths))\n",
    "train_pos_img_dataset = train_pos_img_dataset.map(load_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_neg_img_dataset = tf.data.Dataset.from_tensor_slices(list(train_n_img_paths))\n",
    "train_neg_img_dataset = train_neg_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "test_pos_img_dataset = tf.data.Dataset.from_tensor_slices(list(test_p_img_paths))\n",
    "test_pos_img_dataset = test_pos_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_neg_img_dataset = tf.data.Dataset.from_tensor_slices(list(test_n_img_paths))\n",
    "test_neg_img_dataset = test_neg_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_pos_img_dataset = tf.data.Dataset.from_tensor_slices(list(val_p_img_paths))\n",
    "val_pos_img_dataset = val_pos_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_neg_img_dataset = tf.data.Dataset.from_tensor_slices(list(val_n_img_paths))\n",
    "val_neg_img_dataset = val_neg_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_neg_img_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all datasets (Train, Validation, Test) from each individual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ZipDataset shapes: ((), (240, 240, 3), (240, 240, 3), ()), types: (tf.string, tf.float32, tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((None,), (None, 240, 240, 3), (None, 240, 240, 3), (None,)), types: (tf.string, tf.float32, tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((None,), (None, 240, 240, 3), (None, 240, 240, 3), (None,)), types: (tf.string, tf.float32, tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_combined_dataset = tf.data.Dataset.zip((train_query_dataset,\n",
    "                                        train_pos_img_dataset, \n",
    "                                        train_neg_img_dataset, \n",
    "                                        train_position_bias_dataset))\n",
    "\n",
    "test_combined_dataset = tf.data.Dataset.zip((test_query_dataset,\n",
    "                                        test_pos_img_dataset, \n",
    "                                        test_neg_img_dataset, \n",
    "                                        test_position_bias_dataset))\n",
    "\n",
    "val_combined_dataset = tf.data.Dataset.zip((val_query_dataset,\n",
    "                                        val_pos_img_dataset, \n",
    "                                        val_neg_img_dataset, \n",
    "                                        val_position_bias_dataset))\n",
    "BATCH_SIZE = 4\n",
    "# added august 11, removed .shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_combined_dataset.batch(BATCH_SIZE) #dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_combined_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_combined_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "train_combined_dataset, train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Tape Training on the batch dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/src/train_790/checkpoints/'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/data/src/train_{}/checkpoints/\".format(n_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/src/train_790/objects/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding this in a separate cell because if you run the training cellmany times, the loss_plot array will be reset\n",
    "import time\n",
    "NB_EPOCHS = 10\n",
    "load_losses = False\n",
    "learning_rate = 0.000001\n",
    "margin = 1\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD LOSSES\n",
    "new_dir = \"/data/src/train_{}/\".format(n_samples)\n",
    "if load_losses == True:\n",
    "    results_dir = new_dir + 'loss/'\n",
    "    with open(results_dir+ 'train_loss_plot{}.pkl'.format(n_samples), 'rb') as f:\n",
    "        train_loss_plot = pickle.load(f) \n",
    "\n",
    "    with open(results_dir+ 'val_loss_plot{}.pkl'.format(n_samples), 'rb') as f:\n",
    "        val_loss_plot = pickle.load(f) \n",
    "\n",
    "    with open(results_dir+ 'val_loss_history{}.pkl'.format(n_samples), 'rb') as f:\n",
    "        val_loss_history = pickle.load(f) \n",
    "\n",
    "    with open(results_dir+ 'train_loss_history{}.pkl'.format(n_samples), 'rb') as f:\n",
    "        loss_history = pickle.load(f)\n",
    "else:\n",
    "    train_loss_plot = []\n",
    "    val_loss_plot = []\n",
    "    val_loss_history = []\n",
    "    loss_history = []\n",
    "    margin = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Initializing from scratch.\n"
     ]
    }
   ],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    start_epoch = 0\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    triplet_model.compile(optimizer = optimizer)\n",
    "\n",
    "    checkpoint_path = \"/data/src/train_{}/checkpoints/\".format(n_samples)\n",
    "    checkpoint_dir = os.path.join(checkpoint_path, \"ckpt_{epoch}\")\n",
    "\n",
    "    ckpt = tf.train.Checkpoint(model=triplet_model,\n",
    "                               image_model=image_model,\n",
    "                               text_model=text_model,\n",
    "                               optimizer=optimizer,\n",
    "                               train_dataset= train_dataset, val_dataset= val_dataset)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep = 5)\n",
    "\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)  # restoring the latest checkpoint in checkpoint_path\n",
    "        print(\"******* Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"******* Initializing from scratch.\")\n",
    "    #ckpt_manager, start_epoch = get_checkpoints(triplet_model, image_model, text_model, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with triplet loss based on Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_word_ids tf.Tensor(\n",
      "[[   101  22868  30498    102      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [   101  64101  46085    102      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [   101  23980  26604    102      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [   101 218311    102      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]], shape=(4, 40), dtype=int32)\n",
      "logits [<tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
      "array([[ 0.        ,  0.08737322,  0.34351358, ..., -1.0837562 ,\n",
      "        -0.4428804 ,  0.64991206],\n",
      "       [ 0.        , -1.153798  ,  0.71086663, ..., -1.8926488 ,\n",
      "         0.05919425, -0.8815232 ],\n",
      "       [ 1.0842258 , -0.        ,  0.44927815, ..., -3.0314324 ,\n",
      "        -0.22908096,  0.87218356],\n",
      "       [ 1.7819926 ,  0.85019463,  0.        , ..., -1.2229642 ,\n",
      "        -0.0413996 ,  0.58513254]], dtype=float32)>, <tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
      "array([[-0.        , -0.037579  , -0.40932086, ..., -0.04649156,\n",
      "        -0.02447222,  0.19053365],\n",
      "       [-0.46270603,  0.        ,  0.        , ...,  0.20372334,\n",
      "        -0.        , -0.21419764],\n",
      "       [ 0.5986704 ,  0.79224044, -0.33590147, ...,  0.02735048,\n",
      "        -0.70570576,  1.7050868 ],\n",
      "       [ 0.32078177,  0.6576502 , -0.        , ...,  0.        ,\n",
      "         0.8311222 ,  0.        ]], dtype=float32)>, <tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
      "array([[ 0.20270237,  0.28241047, -0.9305306 , ...,  0.17727853,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.10130989,  0.        ,  0.        , ...,  0.41267693,\n",
      "         0.02070229,  0.3946603 ],\n",
      "       [ 0.7449172 ,  0.        ,  0.03481558, ..., -0.19298129,\n",
      "        -0.0596446 ,  0.5998816 ],\n",
      "       [-0.43710813,  0.5108195 ,  0.10987216, ...,  0.33480024,\n",
      "        -0.34875205,  0.        ]], dtype=float32)>]\n",
      "tf.Tensor([2.5364692], shape=(1,), dtype=float32)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[501153,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-425973c654ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbatch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_bias_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_bias_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-425973c654ad>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(query_batch, pos_batch, neg_batch, position_bias_batch, triplet_model, optimizer, loss_history, margin)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m  \u001b[0;31m# is it batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    547\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m           kwargs={\n\u001b[0;32m--> 549\u001b[0;31m               \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m           })\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   2714\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 2715\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2720\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   2721\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2722\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2723\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    631\u001b[0m                               \"update_\" + var.op.name, skip_on_eager=True):\n\u001b[1;32m    632\u001b[0m             update_ops.extend(distribution.extended.update(\n\u001b[0;32m--> 633\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2298\u001b[0m         fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2299\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2300\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2955\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2959\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    602\u001b[0m           \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         return self._resource_apply_sparse_duplicate_indices(\n\u001b[0;32m--> 604\u001b[0;31m             grad.values, var, grad.indices, **apply_kwargs)\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_resource_apply_sparse_duplicate_indices\u001b[0;34m(self, grad, handle, indices, **kwargs)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         values=grad, indices=indices)\n\u001b[1;32m   1125\u001b[0m     return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n\u001b[0;32m-> 1126\u001b[0;31m                                        **kwargs)\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_resource_apply_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_sparse\u001b[0;34m(self, grad, var, indices, apply_state)\u001b[0m\n\u001b[1;32m    224\u001b[0m       \u001b[0mv_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m       var_update = state_ops.assign_sub(\n\u001b[0;32m--> 226\u001b[0;31m           \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_sqrt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m           use_locking=self._use_locking)\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    507\u001b[0m   \"\"\"\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6164\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6166\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6168\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[501153,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Mul]"
     ]
    }
   ],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    def train_step(query_batch, pos_batch, neg_batch, position_bias_batch, triplet_model, optimizer, loss_history, margin):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            ## updated part specifically for bert\n",
    "            \n",
    "            input_word_ids, input_mask, segment_ids = bert_encode(query_batch.numpy(), text_model)\n",
    "            print('input_word_ids',input_word_ids)\n",
    "            inputs = [input_word_ids, input_mask, segment_ids, pos_batch, neg_batch, position_bias_batch]\n",
    "    \n",
    "            logits = triplet_model(inputs, training=True)\n",
    "            print('logits',logits)\n",
    "            loss_value = triplet_loss_distance(logits, position_bias_batch,margin)  ### batch loss\n",
    "            \n",
    "        print(loss_value)\n",
    "        ## all batch losses\n",
    "        loss_history.append(loss_value.numpy().mean())\n",
    "        grads = tape.gradient(loss_value, triplet_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, triplet_model.trainable_variables))\n",
    "\n",
    "        return loss_value.numpy().mean(), loss_history, logits  # is it batch loss\n",
    "    \n",
    "######################################################################################\n",
    "\n",
    "    for epoch in range(start_epoch, NB_EPOCHS):\n",
    "        \n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        val_total_loss = 0\n",
    "\n",
    "        for (batch, (query_batch, pos_batch, neg_batch, position_bias_batch)) in enumerate(train_dataset):\n",
    "            batch_sample = (query_batch, pos_batch, neg_batch, position_bias_batch)\n",
    "            \n",
    "            batch_loss, loss_history, logits = train_step(query_batch, pos_batch, neg_batch, position_bias_batch, triplet_model, optimizer, loss_history, margin)\n",
    "            total_loss += batch_loss\n",
    "            \n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "\n",
    "        # storing the epoch end loss value to plot later\n",
    "        train_loss_plot.append(total_loss / len(loss_history))  # append(total_loss / BATCH_SIZE)\n",
    "\n",
    "        #if epoch % 2 == 0:\n",
    "        save_path = ckpt_manager.save()\n",
    "        print(\"Saved checkpoint for epoch {}\".format(epoch))\n",
    "        new_dir ='/data/src/train_{}/'.format(n_samples)\n",
    "        results_dir = new_dir + 'loss/'\n",
    "        with open( results_dir + 'train_loss_plot{}.pkl'.format(n_samples), 'wb') as f:\n",
    "            pickle.dump(train_loss_plot, f)\n",
    "\n",
    "        with open( results_dir+ 'val_loss_plot{}.pkl'.format(n_samples), 'wb') as f:\n",
    "            pickle.dump(val_loss_plot, f)\n",
    "\n",
    "        with open(results_dir+ 'val_loss_history{}.pkl'.format(n_samples), 'wb') as f:\n",
    "            pickle.dump(val_loss_history, f)\n",
    "\n",
    "        with open(results_dir+ 'train_loss_history{}.pkl'.format(n_samples), 'wb') as f:\n",
    "            pickle.dump(loss_history, f)\n",
    "\n",
    "        print('Epoch {} Loss {:.6f}'.format(epoch + 1, total_loss / len(loss_history)))  # total_loss/BATCH_SIZE))\n",
    "        \n",
    "        # ****** VALIDATION : Run a validation loop at the end of each epoch.\n",
    "        for (batch, (query_batch, pos_batch, neg_batch, position_bias_batch)) in enumerate(val_dataset):\n",
    "            val_logits = triplet_model([query_batch,\n",
    "                                        pos_batch,\n",
    "                                        neg_batch,\n",
    "                                        position_bias_batch],\n",
    "                                       training=False)\n",
    "\n",
    "            val_loss_value = triplet_loss_distance(val_logits, position_bias_batch)  ### batch loss\n",
    "            val_loss_history.append(val_loss_value)\n",
    "            val_total_loss += val_loss_value\n",
    "\n",
    "        # storing val loss value to plot later\n",
    "        val_loss_plot.append(val_total_loss / len(val_loss_history))\n",
    "        print('Validation epoch {} Loss {}'.format(epoch + 1, val_total_loss / len(val_loss_history)))  # total_loss/BATCH_SIZE))\n",
    "\n",
    "        print('Time taken for 1 epoch {} sec'.format(time.time() - start))\n",
    "        print('Epoch {} finished ------ \\n'.format(epoch))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[   101,  22868,  30498,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101,  64101,  46085,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101,  23980,  26604,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101, 218311,    102,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]],\n",
      "      dtype=int32)>, <tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, <tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[   101,  22868,  30498,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101,  64101,  46085,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101,  23980,  26604,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101, 218311,    102,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]],\n",
      "      dtype=int32)>, <tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, <tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[   101,  22868,  30498,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101,  64101,  46085,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101,  23980,  26604,    102,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0],\n",
      "       [   101, 218311,    102,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]],\n",
      "      dtype=int32)>, <tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, <tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in train_query_dataset.take(3): ######### Yay!!\n",
    "    print(bert_encode(query_batch.numpy(), text_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 32), dtype=int32, numpy=\n",
       "array([[   101,  22868,  30498,    102,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [   101,  64101,  46085,    102,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [   101,  23980,  26604,    102,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [   101, 218311,    102,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(batch_sample)\n",
    "query_batch = batch_sample[0]\n",
    "input_word_ids, input_mask, segment_ids = bert_encode(query_batch.numpy(), text_model)\n",
    "input_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
       "array([[ 0.6686137 ,  0.6123152 ,  0.8213848 , ...,  0.78195745,\n",
       "         0.07649039, -0.60207266],\n",
       "       [ 0.09606467, -0.27259463,  1.3260382 , ...,  0.3839053 ,\n",
       "        -0.12806806, -1.5693829 ],\n",
       "       [ 0.603415  ,  0.89972687,  1.3404877 , ...,  0.09875773,\n",
       "        -0.2250618 , -1.2791427 ],\n",
       "       [ 0.9251202 ,  0.36757737,  0.21447581, ...,  0.9173925 ,\n",
       "        -0.36847535, -0.77529794]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_anchor = text_model([input_word_ids, input_mask,  segment_ids])\n",
    "encoded_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.1158657 ,  1.3427246 , ...,  1.4075227 ,\n",
       "          0.        , -0.        ],\n",
       "        [ 0.1255609 , -0.2973969 ,  0.        , ...,  0.        ,\n",
       "         -0.0293135 , -0.        ],\n",
       "        [ 0.4839004 ,  1.1726831 ,  0.        , ..., -0.12468328,\n",
       "         -0.        , -2.176737  ],\n",
       "        [ 1.3396591 ,  0.8319334 ,  0.14227265, ...,  1.0821208 ,\n",
       "         -0.67129034, -1.1767585 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
       " array([[-0.35189137, -0.25714773,  0.258901  , ..., -0.        ,\n",
       "          0.00804364,  0.3526557 ],\n",
       "        [-0.7480834 , -0.        , -0.70175064, ..., -0.        ,\n",
       "         -0.09351961,  0.27683884],\n",
       "        [-1.9806765 , -0.7743642 , -0.        , ..., -0.        ,\n",
       "         -0.        , -0.8221711 ],\n",
       "        [-1.1468674 , -0.20100184,  0.        , ..., -0.        ,\n",
       "          0.04316418, -0.04658893]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.04044246, -0.        , ..., -0.27318126,\n",
       "          0.15530334, -0.27381635],\n",
       "        [-1.1360959 , -0.915002  , -0.53310615, ..., -0.4943595 ,\n",
       "         -0.14885221, -0.        ],\n",
       "        [-1.6065998 , -0.76512516, -0.1285873 , ..., -0.4373098 ,\n",
       "         -0.11508854, -0.30596563],\n",
       "        [-0.9907809 , -0.39877382,  0.34376496, ..., -0.        ,\n",
       "         -0.        ,  0.44427025]], dtype=float32)>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [input_word_ids, input_mask, segment_ids, pos_batch, neg_batch, position_bias_batch]\n",
    "logits = triplet_model(inputs, training=True)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.0228841], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_value = triplet_loss_distance(logits,position_bias_batch,  margin)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3.0228841], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    print(loss_value)\n",
    "    ## all batch losses\n",
    "    loss_history.append(loss_value.numpy().mean())\n",
    "    grads = tape.gradient(loss_value, triplet_model.trainable_variables)\n",
    "    grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'word_embeddings/embeddings:0' shape=(501153, 768) dtype=float32, numpy=<unavailable>>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_model.trainable_variables[0] ### this is the largest tensor from embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['word_embeddings/embeddings:0', 'position_embedding/embeddings:0', 'type_embeddings/embeddings:0', 'embeddings/layer_norm/gamma:0', 'embeddings/layer_norm/beta:0', 'transformer/layer_0/self_attention/query/kernel:0', 'transformer/layer_0/self_attention/query/bias:0', 'transformer/layer_0/self_attention/key/kernel:0', 'transformer/layer_0/self_attention/key/bias:0', 'transformer/layer_0/self_attention/value/kernel:0', 'transformer/layer_0/self_attention/value/bias:0', 'transformer/layer_0/self_attention/attention_output/kernel:0', 'transformer/layer_0/self_attention/attention_output/bias:0', 'transformer/layer_0/self_attention_layer_norm/gamma:0', 'transformer/layer_0/self_attention_layer_norm/beta:0', 'transformer/layer_0/intermediate/kernel:0', 'transformer/layer_0/intermediate/bias:0', 'transformer/layer_0/output/kernel:0', 'transformer/layer_0/output/bias:0', 'transformer/layer_0/output_layer_norm/gamma:0', 'transformer/layer_0/output_layer_norm/beta:0', 'transformer/layer_1/self_attention/query/kernel:0', 'transformer/layer_1/self_attention/query/bias:0', 'transformer/layer_1/self_attention/key/kernel:0', 'transformer/layer_1/self_attention/key/bias:0', 'transformer/layer_1/self_attention/value/kernel:0', 'transformer/layer_1/self_attention/value/bias:0', 'transformer/layer_1/self_attention/attention_output/kernel:0', 'transformer/layer_1/self_attention/attention_output/bias:0', 'transformer/layer_1/self_attention_layer_norm/gamma:0', 'transformer/layer_1/self_attention_layer_norm/beta:0', 'transformer/layer_1/intermediate/kernel:0', 'transformer/layer_1/intermediate/bias:0', 'transformer/layer_1/output/kernel:0', 'transformer/layer_1/output/bias:0', 'transformer/layer_1/output_layer_norm/gamma:0', 'transformer/layer_1/output_layer_norm/beta:0', 'transformer/layer_2/self_attention/query/kernel:0', 'transformer/layer_2/self_attention/query/bias:0', 'transformer/layer_2/self_attention/key/kernel:0', 'transformer/layer_2/self_attention/key/bias:0', 'transformer/layer_2/self_attention/value/kernel:0', 'transformer/layer_2/self_attention/value/bias:0', 'transformer/layer_2/self_attention/attention_output/kernel:0', 'transformer/layer_2/self_attention/attention_output/bias:0', 'transformer/layer_2/self_attention_layer_norm/gamma:0', 'transformer/layer_2/self_attention_layer_norm/beta:0', 'transformer/layer_2/intermediate/kernel:0', 'transformer/layer_2/intermediate/bias:0', 'transformer/layer_2/output/kernel:0', 'transformer/layer_2/output/bias:0', 'transformer/layer_2/output_layer_norm/gamma:0', 'transformer/layer_2/output_layer_norm/beta:0', 'transformer/layer_3/self_attention/query/kernel:0', 'transformer/layer_3/self_attention/query/bias:0', 'transformer/layer_3/self_attention/key/kernel:0', 'transformer/layer_3/self_attention/key/bias:0', 'transformer/layer_3/self_attention/value/kernel:0', 'transformer/layer_3/self_attention/value/bias:0', 'transformer/layer_3/self_attention/attention_output/kernel:0', 'transformer/layer_3/self_attention/attention_output/bias:0', 'transformer/layer_3/self_attention_layer_norm/gamma:0', 'transformer/layer_3/self_attention_layer_norm/beta:0', 'transformer/layer_3/intermediate/kernel:0', 'transformer/layer_3/intermediate/bias:0', 'transformer/layer_3/output/kernel:0', 'transformer/layer_3/output/bias:0', 'transformer/layer_3/output_layer_norm/gamma:0', 'transformer/layer_3/output_layer_norm/beta:0', 'transformer/layer_4/self_attention/query/kernel:0', 'transformer/layer_4/self_attention/query/bias:0', 'transformer/layer_4/self_attention/key/kernel:0', 'transformer/layer_4/self_attention/key/bias:0', 'transformer/layer_4/self_attention/value/kernel:0', 'transformer/layer_4/self_attention/value/bias:0', 'transformer/layer_4/self_attention/attention_output/kernel:0', 'transformer/layer_4/self_attention/attention_output/bias:0', 'transformer/layer_4/self_attention_layer_norm/gamma:0', 'transformer/layer_4/self_attention_layer_norm/beta:0', 'transformer/layer_4/intermediate/kernel:0', 'transformer/layer_4/intermediate/bias:0', 'transformer/layer_4/output/kernel:0', 'transformer/layer_4/output/bias:0', 'transformer/layer_4/output_layer_norm/gamma:0', 'transformer/layer_4/output_layer_norm/beta:0', 'transformer/layer_5/self_attention/query/kernel:0', 'transformer/layer_5/self_attention/query/bias:0', 'transformer/layer_5/self_attention/key/kernel:0', 'transformer/layer_5/self_attention/key/bias:0', 'transformer/layer_5/self_attention/value/kernel:0', 'transformer/layer_5/self_attention/value/bias:0', 'transformer/layer_5/self_attention/attention_output/kernel:0', 'transformer/layer_5/self_attention/attention_output/bias:0', 'transformer/layer_5/self_attention_layer_norm/gamma:0', 'transformer/layer_5/self_attention_layer_norm/beta:0', 'transformer/layer_5/intermediate/kernel:0', 'transformer/layer_5/intermediate/bias:0', 'transformer/layer_5/output/kernel:0', 'transformer/layer_5/output/bias:0', 'transformer/layer_5/output_layer_norm/gamma:0', 'transformer/layer_5/output_layer_norm/beta:0', 'transformer/layer_6/self_attention/query/kernel:0', 'transformer/layer_6/self_attention/query/bias:0', 'transformer/layer_6/self_attention/key/kernel:0', 'transformer/layer_6/self_attention/key/bias:0', 'transformer/layer_6/self_attention/value/kernel:0', 'transformer/layer_6/self_attention/value/bias:0', 'transformer/layer_6/self_attention/attention_output/kernel:0', 'transformer/layer_6/self_attention/attention_output/bias:0', 'transformer/layer_6/self_attention_layer_norm/gamma:0', 'transformer/layer_6/self_attention_layer_norm/beta:0', 'transformer/layer_6/intermediate/kernel:0', 'transformer/layer_6/intermediate/bias:0', 'transformer/layer_6/output/kernel:0', 'transformer/layer_6/output/bias:0', 'transformer/layer_6/output_layer_norm/gamma:0', 'transformer/layer_6/output_layer_norm/beta:0', 'transformer/layer_7/self_attention/query/kernel:0', 'transformer/layer_7/self_attention/query/bias:0', 'transformer/layer_7/self_attention/key/kernel:0', 'transformer/layer_7/self_attention/key/bias:0', 'transformer/layer_7/self_attention/value/kernel:0', 'transformer/layer_7/self_attention/value/bias:0', 'transformer/layer_7/self_attention/attention_output/kernel:0', 'transformer/layer_7/self_attention/attention_output/bias:0', 'transformer/layer_7/self_attention_layer_norm/gamma:0', 'transformer/layer_7/self_attention_layer_norm/beta:0', 'transformer/layer_7/intermediate/kernel:0', 'transformer/layer_7/intermediate/bias:0', 'transformer/layer_7/output/kernel:0', 'transformer/layer_7/output/bias:0', 'transformer/layer_7/output_layer_norm/gamma:0', 'transformer/layer_7/output_layer_norm/beta:0', 'transformer/layer_8/self_attention/query/kernel:0', 'transformer/layer_8/self_attention/query/bias:0', 'transformer/layer_8/self_attention/key/kernel:0', 'transformer/layer_8/self_attention/key/bias:0', 'transformer/layer_8/self_attention/value/kernel:0', 'transformer/layer_8/self_attention/value/bias:0', 'transformer/layer_8/self_attention/attention_output/kernel:0', 'transformer/layer_8/self_attention/attention_output/bias:0', 'transformer/layer_8/self_attention_layer_norm/gamma:0', 'transformer/layer_8/self_attention_layer_norm/beta:0', 'transformer/layer_8/intermediate/kernel:0', 'transformer/layer_8/intermediate/bias:0', 'transformer/layer_8/output/kernel:0', 'transformer/layer_8/output/bias:0', 'transformer/layer_8/output_layer_norm/gamma:0', 'transformer/layer_8/output_layer_norm/beta:0', 'transformer/layer_9/self_attention/query/kernel:0', 'transformer/layer_9/self_attention/query/bias:0', 'transformer/layer_9/self_attention/key/kernel:0', 'transformer/layer_9/self_attention/key/bias:0', 'transformer/layer_9/self_attention/value/kernel:0', 'transformer/layer_9/self_attention/value/bias:0', 'transformer/layer_9/self_attention/attention_output/kernel:0', 'transformer/layer_9/self_attention/attention_output/bias:0', 'transformer/layer_9/self_attention_layer_norm/gamma:0', 'transformer/layer_9/self_attention_layer_norm/beta:0', 'transformer/layer_9/intermediate/kernel:0', 'transformer/layer_9/intermediate/bias:0', 'transformer/layer_9/output/kernel:0', 'transformer/layer_9/output/bias:0', 'transformer/layer_9/output_layer_norm/gamma:0', 'transformer/layer_9/output_layer_norm/beta:0', 'transformer/layer_10/self_attention/query/kernel:0', 'transformer/layer_10/self_attention/query/bias:0', 'transformer/layer_10/self_attention/key/kernel:0', 'transformer/layer_10/self_attention/key/bias:0', 'transformer/layer_10/self_attention/value/kernel:0', 'transformer/layer_10/self_attention/value/bias:0', 'transformer/layer_10/self_attention/attention_output/kernel:0', 'transformer/layer_10/self_attention/attention_output/bias:0', 'transformer/layer_10/self_attention_layer_norm/gamma:0', 'transformer/layer_10/self_attention_layer_norm/beta:0', 'transformer/layer_10/intermediate/kernel:0', 'transformer/layer_10/intermediate/bias:0', 'transformer/layer_10/output/kernel:0', 'transformer/layer_10/output/bias:0', 'transformer/layer_10/output_layer_norm/gamma:0', 'transformer/layer_10/output_layer_norm/beta:0', 'transformer/layer_11/self_attention/query/kernel:0', 'transformer/layer_11/self_attention/query/bias:0', 'transformer/layer_11/self_attention/key/kernel:0', 'transformer/layer_11/self_attention/key/bias:0', 'transformer/layer_11/self_attention/value/kernel:0', 'transformer/layer_11/self_attention/value/bias:0', 'transformer/layer_11/self_attention/attention_output/kernel:0', 'transformer/layer_11/self_attention/attention_output/bias:0', 'transformer/layer_11/self_attention_layer_norm/gamma:0', 'transformer/layer_11/self_attention_layer_norm/beta:0', 'transformer/layer_11/intermediate/kernel:0', 'transformer/layer_11/intermediate/bias:0', 'transformer/layer_11/output/kernel:0', 'transformer/layer_11/output/bias:0', 'transformer/layer_11/output_layer_norm/gamma:0', 'transformer/layer_11/output_layer_norm/beta:0', 'pooler_transform/kernel:0', 'pooler_transform/bias:0', 'dense/kernel:0', 'dense/bias:0', 'conv2d/kernel:0', 'batch_normalization/beta:0', 'conv2d_1/kernel:0', 'batch_normalization_1/beta:0', 'conv2d_2/kernel:0', 'batch_normalization_2/beta:0', 'conv2d_3/kernel:0', 'batch_normalization_3/beta:0', 'conv2d_4/kernel:0', 'batch_normalization_4/beta:0', 'conv2d_8/kernel:0', 'batch_normalization_8/beta:0', 'conv2d_6/kernel:0', 'conv2d_9/kernel:0', 'batch_normalization_6/beta:0', 'batch_normalization_9/beta:0', 'conv2d_5/kernel:0', 'conv2d_7/kernel:0', 'conv2d_10/kernel:0', 'conv2d_11/kernel:0', 'batch_normalization_5/beta:0', 'batch_normalization_7/beta:0', 'batch_normalization_10/beta:0', 'batch_normalization_11/beta:0', 'conv2d_15/kernel:0', 'batch_normalization_15/beta:0', 'conv2d_13/kernel:0', 'conv2d_16/kernel:0', 'batch_normalization_13/beta:0', 'batch_normalization_16/beta:0', 'conv2d_12/kernel:0', 'conv2d_14/kernel:0', 'conv2d_17/kernel:0', 'conv2d_18/kernel:0', 'batch_normalization_12/beta:0', 'batch_normalization_14/beta:0', 'batch_normalization_17/beta:0', 'batch_normalization_18/beta:0', 'conv2d_22/kernel:0', 'batch_normalization_22/beta:0', 'conv2d_20/kernel:0', 'conv2d_23/kernel:0', 'batch_normalization_20/beta:0', 'batch_normalization_23/beta:0', 'conv2d_19/kernel:0', 'conv2d_21/kernel:0', 'conv2d_24/kernel:0', 'conv2d_25/kernel:0', 'batch_normalization_19/beta:0', 'batch_normalization_21/beta:0', 'batch_normalization_24/beta:0', 'batch_normalization_25/beta:0', 'conv2d_27/kernel:0', 'batch_normalization_27/beta:0', 'conv2d_28/kernel:0', 'batch_normalization_28/beta:0', 'conv2d_26/kernel:0', 'conv2d_29/kernel:0', 'batch_normalization_26/beta:0', 'batch_normalization_29/beta:0', 'conv2d_34/kernel:0', 'batch_normalization_34/beta:0', 'conv2d_35/kernel:0', 'batch_normalization_35/beta:0', 'conv2d_31/kernel:0', 'conv2d_36/kernel:0', 'batch_normalization_31/beta:0', 'batch_normalization_36/beta:0', 'conv2d_32/kernel:0', 'conv2d_37/kernel:0', 'batch_normalization_32/beta:0', 'batch_normalization_37/beta:0', 'conv2d_30/kernel:0', 'conv2d_33/kernel:0', 'conv2d_38/kernel:0', 'conv2d_39/kernel:0', 'batch_normalization_30/beta:0', 'batch_normalization_33/beta:0', 'batch_normalization_38/beta:0', 'batch_normalization_39/beta:0', 'conv2d_44/kernel:0', 'batch_normalization_44/beta:0', 'conv2d_45/kernel:0', 'batch_normalization_45/beta:0', 'conv2d_41/kernel:0', 'conv2d_46/kernel:0', 'batch_normalization_41/beta:0', 'batch_normalization_46/beta:0', 'conv2d_42/kernel:0', 'conv2d_47/kernel:0', 'batch_normalization_42/beta:0', 'batch_normalization_47/beta:0', 'conv2d_40/kernel:0', 'conv2d_43/kernel:0', 'conv2d_48/kernel:0', 'conv2d_49/kernel:0', 'batch_normalization_40/beta:0', 'batch_normalization_43/beta:0', 'batch_normalization_48/beta:0', 'batch_normalization_49/beta:0', 'conv2d_54/kernel:0', 'batch_normalization_54/beta:0', 'conv2d_55/kernel:0', 'batch_normalization_55/beta:0', 'conv2d_51/kernel:0', 'conv2d_56/kernel:0', 'batch_normalization_51/beta:0', 'batch_normalization_56/beta:0', 'conv2d_52/kernel:0', 'conv2d_57/kernel:0', 'batch_normalization_52/beta:0', 'batch_normalization_57/beta:0', 'conv2d_50/kernel:0', 'conv2d_53/kernel:0', 'conv2d_58/kernel:0', 'conv2d_59/kernel:0', 'batch_normalization_50/beta:0', 'batch_normalization_53/beta:0', 'batch_normalization_58/beta:0', 'batch_normalization_59/beta:0', 'conv2d_64/kernel:0', 'batch_normalization_64/beta:0', 'conv2d_65/kernel:0', 'batch_normalization_65/beta:0', 'conv2d_61/kernel:0', 'conv2d_66/kernel:0', 'batch_normalization_61/beta:0', 'batch_normalization_66/beta:0', 'conv2d_62/kernel:0', 'conv2d_67/kernel:0', 'batch_normalization_62/beta:0', 'batch_normalization_67/beta:0', 'conv2d_60/kernel:0', 'conv2d_63/kernel:0', 'conv2d_68/kernel:0', 'conv2d_69/kernel:0', 'batch_normalization_60/beta:0', 'batch_normalization_63/beta:0', 'batch_normalization_68/beta:0', 'batch_normalization_69/beta:0', 'conv2d_72/kernel:0', 'batch_normalization_72/beta:0', 'conv2d_73/kernel:0', 'batch_normalization_73/beta:0', 'conv2d_70/kernel:0', 'conv2d_74/kernel:0', 'batch_normalization_70/beta:0', 'batch_normalization_74/beta:0', 'conv2d_71/kernel:0', 'conv2d_75/kernel:0', 'batch_normalization_71/beta:0', 'batch_normalization_75/beta:0', 'conv2d_80/kernel:0', 'batch_normalization_80/beta:0', 'conv2d_77/kernel:0', 'conv2d_81/kernel:0', 'batch_normalization_77/beta:0', 'batch_normalization_81/beta:0', 'conv2d_78/kernel:0', 'conv2d_79/kernel:0', 'conv2d_82/kernel:0', 'conv2d_83/kernel:0', 'conv2d_76/kernel:0', 'batch_normalization_78/beta:0', 'batch_normalization_79/beta:0', 'batch_normalization_82/beta:0', 'batch_normalization_83/beta:0', 'conv2d_84/kernel:0', 'batch_normalization_76/beta:0', 'batch_normalization_84/beta:0', 'conv2d_89/kernel:0', 'batch_normalization_89/beta:0', 'conv2d_86/kernel:0', 'conv2d_90/kernel:0', 'batch_normalization_86/beta:0', 'batch_normalization_90/beta:0', 'conv2d_87/kernel:0', 'conv2d_88/kernel:0', 'conv2d_91/kernel:0', 'conv2d_92/kernel:0', 'conv2d_85/kernel:0', 'batch_normalization_87/beta:0', 'batch_normalization_88/beta:0', 'batch_normalization_91/beta:0', 'batch_normalization_92/beta:0', 'conv2d_93/kernel:0', 'batch_normalization_85/beta:0', 'batch_normalization_93/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-3f526f3eb4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    511\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1271\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1272\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['word_embeddings/embeddings:0', 'position_embedding/embeddings:0', 'type_embeddings/embeddings:0', 'embeddings/layer_norm/gamma:0', 'embeddings/layer_norm/beta:0', 'transformer/layer_0/self_attention/query/kernel:0', 'transformer/layer_0/self_attention/query/bias:0', 'transformer/layer_0/self_attention/key/kernel:0', 'transformer/layer_0/self_attention/key/bias:0', 'transformer/layer_0/self_attention/value/kernel:0', 'transformer/layer_0/self_attention/value/bias:0', 'transformer/layer_0/self_attention/attention_output/kernel:0', 'transformer/layer_0/self_attention/attention_output/bias:0', 'transformer/layer_0/self_attention_layer_norm/gamma:0', 'transformer/layer_0/self_attention_layer_norm/beta:0', 'transformer/layer_0/intermediate/kernel:0', 'transformer/layer_0/intermediate/bias:0', 'transformer/layer_0/output/kernel:0', 'transformer/layer_0/output/bias:0', 'transformer/layer_0/output_layer_norm/gamma:0', 'transformer/layer_0/output_layer_norm/beta:0', 'transformer/layer_1/self_attention/query/kernel:0', 'transformer/layer_1/self_attention/query/bias:0', 'transformer/layer_1/self_attention/key/kernel:0', 'transformer/layer_1/self_attention/key/bias:0', 'transformer/layer_1/self_attention/value/kernel:0', 'transformer/layer_1/self_attention/value/bias:0', 'transformer/layer_1/self_attention/attention_output/kernel:0', 'transformer/layer_1/self_attention/attention_output/bias:0', 'transformer/layer_1/self_attention_layer_norm/gamma:0', 'transformer/layer_1/self_attention_layer_norm/beta:0', 'transformer/layer_1/intermediate/kernel:0', 'transformer/layer_1/intermediate/bias:0', 'transformer/layer_1/output/kernel:0', 'transformer/layer_1/output/bias:0', 'transformer/layer_1/output_layer_norm/gamma:0', 'transformer/layer_1/output_layer_norm/beta:0', 'transformer/layer_2/self_attention/query/kernel:0', 'transformer/layer_2/self_attention/query/bias:0', 'transformer/layer_2/self_attention/key/kernel:0', 'transformer/layer_2/self_attention/key/bias:0', 'transformer/layer_2/self_attention/value/kernel:0', 'transformer/layer_2/self_attention/value/bias:0', 'transformer/layer_2/self_attention/attention_output/kernel:0', 'transformer/layer_2/self_attention/attention_output/bias:0', 'transformer/layer_2/self_attention_layer_norm/gamma:0', 'transformer/layer_2/self_attention_layer_norm/beta:0', 'transformer/layer_2/intermediate/kernel:0', 'transformer/layer_2/intermediate/bias:0', 'transformer/layer_2/output/kernel:0', 'transformer/layer_2/output/bias:0', 'transformer/layer_2/output_layer_norm/gamma:0', 'transformer/layer_2/output_layer_norm/beta:0', 'transformer/layer_3/self_attention/query/kernel:0', 'transformer/layer_3/self_attention/query/bias:0', 'transformer/layer_3/self_attention/key/kernel:0', 'transformer/layer_3/self_attention/key/bias:0', 'transformer/layer_3/self_attention/value/kernel:0', 'transformer/layer_3/self_attention/value/bias:0', 'transformer/layer_3/self_attention/attention_output/kernel:0', 'transformer/layer_3/self_attention/attention_output/bias:0', 'transformer/layer_3/self_attention_layer_norm/gamma:0', 'transformer/layer_3/self_attention_layer_norm/beta:0', 'transformer/layer_3/intermediate/kernel:0', 'transformer/layer_3/intermediate/bias:0', 'transformer/layer_3/output/kernel:0', 'transformer/layer_3/output/bias:0', 'transformer/layer_3/output_layer_norm/gamma:0', 'transformer/layer_3/output_layer_norm/beta:0', 'transformer/layer_4/self_attention/query/kernel:0', 'transformer/layer_4/self_attention/query/bias:0', 'transformer/layer_4/self_attention/key/kernel:0', 'transformer/layer_4/self_attention/key/bias:0', 'transformer/layer_4/self_attention/value/kernel:0', 'transformer/layer_4/self_attention/value/bias:0', 'transformer/layer_4/self_attention/attention_output/kernel:0', 'transformer/layer_4/self_attention/attention_output/bias:0', 'transformer/layer_4/self_attention_layer_norm/gamma:0', 'transformer/layer_4/self_attention_layer_norm/beta:0', 'transformer/layer_4/intermediate/kernel:0', 'transformer/layer_4/intermediate/bias:0', 'transformer/layer_4/output/kernel:0', 'transformer/layer_4/output/bias:0', 'transformer/layer_4/output_layer_norm/gamma:0', 'transformer/layer_4/output_layer_norm/beta:0', 'transformer/layer_5/self_attention/query/kernel:0', 'transformer/layer_5/self_attention/query/bias:0', 'transformer/layer_5/self_attention/key/kernel:0', 'transformer/layer_5/self_attention/key/bias:0', 'transformer/layer_5/self_attention/value/kernel:0', 'transformer/layer_5/self_attention/value/bias:0', 'transformer/layer_5/self_attention/attention_output/kernel:0', 'transformer/layer_5/self_attention/attention_output/bias:0', 'transformer/layer_5/self_attention_layer_norm/gamma:0', 'transformer/layer_5/self_attention_layer_norm/beta:0', 'transformer/layer_5/intermediate/kernel:0', 'transformer/layer_5/intermediate/bias:0', 'transformer/layer_5/output/kernel:0', 'transformer/layer_5/output/bias:0', 'transformer/layer_5/output_layer_norm/gamma:0', 'transformer/layer_5/output_layer_norm/beta:0', 'transformer/layer_6/self_attention/query/kernel:0', 'transformer/layer_6/self_attention/query/bias:0', 'transformer/layer_6/self_attention/key/kernel:0', 'transformer/layer_6/self_attention/key/bias:0', 'transformer/layer_6/self_attention/value/kernel:0', 'transformer/layer_6/self_attention/value/bias:0', 'transformer/layer_6/self_attention/attention_output/kernel:0', 'transformer/layer_6/self_attention/attention_output/bias:0', 'transformer/layer_6/self_attention_layer_norm/gamma:0', 'transformer/layer_6/self_attention_layer_norm/beta:0', 'transformer/layer_6/intermediate/kernel:0', 'transformer/layer_6/intermediate/bias:0', 'transformer/layer_6/output/kernel:0', 'transformer/layer_6/output/bias:0', 'transformer/layer_6/output_layer_norm/gamma:0', 'transformer/layer_6/output_layer_norm/beta:0', 'transformer/layer_7/self_attention/query/kernel:0', 'transformer/layer_7/self_attention/query/bias:0', 'transformer/layer_7/self_attention/key/kernel:0', 'transformer/layer_7/self_attention/key/bias:0', 'transformer/layer_7/self_attention/value/kernel:0', 'transformer/layer_7/self_attention/value/bias:0', 'transformer/layer_7/self_attention/attention_output/kernel:0', 'transformer/layer_7/self_attention/attention_output/bias:0', 'transformer/layer_7/self_attention_layer_norm/gamma:0', 'transformer/layer_7/self_attention_layer_norm/beta:0', 'transformer/layer_7/intermediate/kernel:0', 'transformer/layer_7/intermediate/bias:0', 'transformer/layer_7/output/kernel:0', 'transformer/layer_7/output/bias:0', 'transformer/layer_7/output_layer_norm/gamma:0', 'transformer/layer_7/output_layer_norm/beta:0', 'transformer/layer_8/self_attention/query/kernel:0', 'transformer/layer_8/self_attention/query/bias:0', 'transformer/layer_8/self_attention/key/kernel:0', 'transformer/layer_8/self_attention/key/bias:0', 'transformer/layer_8/self_attention/value/kernel:0', 'transformer/layer_8/self_attention/value/bias:0', 'transformer/layer_8/self_attention/attention_output/kernel:0', 'transformer/layer_8/self_attention/attention_output/bias:0', 'transformer/layer_8/self_attention_layer_norm/gamma:0', 'transformer/layer_8/self_attention_layer_norm/beta:0', 'transformer/layer_8/intermediate/kernel:0', 'transformer/layer_8/intermediate/bias:0', 'transformer/layer_8/output/kernel:0', 'transformer/layer_8/output/bias:0', 'transformer/layer_8/output_layer_norm/gamma:0', 'transformer/layer_8/output_layer_norm/beta:0', 'transformer/layer_9/self_attention/query/kernel:0', 'transformer/layer_9/self_attention/query/bias:0', 'transformer/layer_9/self_attention/key/kernel:0', 'transformer/layer_9/self_attention/key/bias:0', 'transformer/layer_9/self_attention/value/kernel:0', 'transformer/layer_9/self_attention/value/bias:0', 'transformer/layer_9/self_attention/attention_output/kernel:0', 'transformer/layer_9/self_attention/attention_output/bias:0', 'transformer/layer_9/self_attention_layer_norm/gamma:0', 'transformer/layer_9/self_attention_layer_norm/beta:0', 'transformer/layer_9/intermediate/kernel:0', 'transformer/layer_9/intermediate/bias:0', 'transformer/layer_9/output/kernel:0', 'transformer/layer_9/output/bias:0', 'transformer/layer_9/output_layer_norm/gamma:0', 'transformer/layer_9/output_layer_norm/beta:0', 'transformer/layer_10/self_attention/query/kernel:0', 'transformer/layer_10/self_attention/query/bias:0', 'transformer/layer_10/self_attention/key/kernel:0', 'transformer/layer_10/self_attention/key/bias:0', 'transformer/layer_10/self_attention/value/kernel:0', 'transformer/layer_10/self_attention/value/bias:0', 'transformer/layer_10/self_attention/attention_output/kernel:0', 'transformer/layer_10/self_attention/attention_output/bias:0', 'transformer/layer_10/self_attention_layer_norm/gamma:0', 'transformer/layer_10/self_attention_layer_norm/beta:0', 'transformer/layer_10/intermediate/kernel:0', 'transformer/layer_10/intermediate/bias:0', 'transformer/layer_10/output/kernel:0', 'transformer/layer_10/output/bias:0', 'transformer/layer_10/output_layer_norm/gamma:0', 'transformer/layer_10/output_layer_norm/beta:0', 'transformer/layer_11/self_attention/query/kernel:0', 'transformer/layer_11/self_attention/query/bias:0', 'transformer/layer_11/self_attention/key/kernel:0', 'transformer/layer_11/self_attention/key/bias:0', 'transformer/layer_11/self_attention/value/kernel:0', 'transformer/layer_11/self_attention/value/bias:0', 'transformer/layer_11/self_attention/attention_output/kernel:0', 'transformer/layer_11/self_attention/attention_output/bias:0', 'transformer/layer_11/self_attention_layer_norm/gamma:0', 'transformer/layer_11/self_attention_layer_norm/beta:0', 'transformer/layer_11/intermediate/kernel:0', 'transformer/layer_11/intermediate/bias:0', 'transformer/layer_11/output/kernel:0', 'transformer/layer_11/output/bias:0', 'transformer/layer_11/output_layer_norm/gamma:0', 'transformer/layer_11/output_layer_norm/beta:0', 'pooler_transform/kernel:0', 'pooler_transform/bias:0', 'dense/kernel:0', 'dense/bias:0', 'conv2d/kernel:0', 'batch_normalization/beta:0', 'conv2d_1/kernel:0', 'batch_normalization_1/beta:0', 'conv2d_2/kernel:0', 'batch_normalization_2/beta:0', 'conv2d_3/kernel:0', 'batch_normalization_3/beta:0', 'conv2d_4/kernel:0', 'batch_normalization_4/beta:0', 'conv2d_8/kernel:0', 'batch_normalization_8/beta:0', 'conv2d_6/kernel:0', 'conv2d_9/kernel:0', 'batch_normalization_6/beta:0', 'batch_normalization_9/beta:0', 'conv2d_5/kernel:0', 'conv2d_7/kernel:0', 'conv2d_10/kernel:0', 'conv2d_11/kernel:0', 'batch_normalization_5/beta:0', 'batch_normalization_7/beta:0', 'batch_normalization_10/beta:0', 'batch_normalization_11/beta:0', 'conv2d_15/kernel:0', 'batch_normalization_15/beta:0', 'conv2d_13/kernel:0', 'conv2d_16/kernel:0', 'batch_normalization_13/beta:0', 'batch_normalization_16/beta:0', 'conv2d_12/kernel:0', 'conv2d_14/kernel:0', 'conv2d_17/kernel:0', 'conv2d_18/kernel:0', 'batch_normalization_12/beta:0', 'batch_normalization_14/beta:0', 'batch_normalization_17/beta:0', 'batch_normalization_18/beta:0', 'conv2d_22/kernel:0', 'batch_normalization_22/beta:0', 'conv2d_20/kernel:0', 'conv2d_23/kernel:0', 'batch_normalization_20/beta:0', 'batch_normalization_23/beta:0', 'conv2d_19/kernel:0', 'conv2d_21/kernel:0', 'conv2d_24/kernel:0', 'conv2d_25/kernel:0', 'batch_normalization_19/beta:0', 'batch_normalization_21/beta:0', 'batch_normalization_24/beta:0', 'batch_normalization_25/beta:0', 'conv2d_27/kernel:0', 'batch_normalization_27/beta:0', 'conv2d_28/kernel:0', 'batch_normalization_28/beta:0', 'conv2d_26/kernel:0', 'conv2d_29/kernel:0', 'batch_normalization_26/beta:0', 'batch_normalization_29/beta:0', 'conv2d_34/kernel:0', 'batch_normalization_34/beta:0', 'conv2d_35/kernel:0', 'batch_normalization_35/beta:0', 'conv2d_31/kernel:0', 'conv2d_36/kernel:0', 'batch_normalization_31/beta:0', 'batch_normalization_36/beta:0', 'conv2d_32/kernel:0', 'conv2d_37/kernel:0', 'batch_normalization_32/beta:0', 'batch_normalization_37/beta:0', 'conv2d_30/kernel:0', 'conv2d_33/kernel:0', 'conv2d_38/kernel:0', 'conv2d_39/kernel:0', 'batch_normalization_30/beta:0', 'batch_normalization_33/beta:0', 'batch_normalization_38/beta:0', 'batch_normalization_39/beta:0', 'conv2d_44/kernel:0', 'batch_normalization_44/beta:0', 'conv2d_45/kernel:0', 'batch_normalization_45/beta:0', 'conv2d_41/kernel:0', 'conv2d_46/kernel:0', 'batch_normalization_41/beta:0', 'batch_normalization_46/beta:0', 'conv2d_42/kernel:0', 'conv2d_47/kernel:0', 'batch_normalization_42/beta:0', 'batch_normalization_47/beta:0', 'conv2d_40/kernel:0', 'conv2d_43/kernel:0', 'conv2d_48/kernel:0', 'conv2d_49/kernel:0', 'batch_normalization_40/beta:0', 'batch_normalization_43/beta:0', 'batch_normalization_48/beta:0', 'batch_normalization_49/beta:0', 'conv2d_54/kernel:0', 'batch_normalization_54/beta:0', 'conv2d_55/kernel:0', 'batch_normalization_55/beta:0', 'conv2d_51/kernel:0', 'conv2d_56/kernel:0', 'batch_normalization_51/beta:0', 'batch_normalization_56/beta:0', 'conv2d_52/kernel:0', 'conv2d_57/kernel:0', 'batch_normalization_52/beta:0', 'batch_normalization_57/beta:0', 'conv2d_50/kernel:0', 'conv2d_53/kernel:0', 'conv2d_58/kernel:0', 'conv2d_59/kernel:0', 'batch_normalization_50/beta:0', 'batch_normalization_53/beta:0', 'batch_normalization_58/beta:0', 'batch_normalization_59/beta:0', 'conv2d_64/kernel:0', 'batch_normalization_64/beta:0', 'conv2d_65/kernel:0', 'batch_normalization_65/beta:0', 'conv2d_61/kernel:0', 'conv2d_66/kernel:0', 'batch_normalization_61/beta:0', 'batch_normalization_66/beta:0', 'conv2d_62/kernel:0', 'conv2d_67/kernel:0', 'batch_normalization_62/beta:0', 'batch_normalization_67/beta:0', 'conv2d_60/kernel:0', 'conv2d_63/kernel:0', 'conv2d_68/kernel:0', 'conv2d_69/kernel:0', 'batch_normalization_60/beta:0', 'batch_normalization_63/beta:0', 'batch_normalization_68/beta:0', 'batch_normalization_69/beta:0', 'conv2d_72/kernel:0', 'batch_normalization_72/beta:0', 'conv2d_73/kernel:0', 'batch_normalization_73/beta:0', 'conv2d_70/kernel:0', 'conv2d_74/kernel:0', 'batch_normalization_70/beta:0', 'batch_normalization_74/beta:0', 'conv2d_71/kernel:0', 'conv2d_75/kernel:0', 'batch_normalization_71/beta:0', 'batch_normalization_75/beta:0', 'conv2d_80/kernel:0', 'batch_normalization_80/beta:0', 'conv2d_77/kernel:0', 'conv2d_81/kernel:0', 'batch_normalization_77/beta:0', 'batch_normalization_81/beta:0', 'conv2d_78/kernel:0', 'conv2d_79/kernel:0', 'conv2d_82/kernel:0', 'conv2d_83/kernel:0', 'conv2d_76/kernel:0', 'batch_normalization_78/beta:0', 'batch_normalization_79/beta:0', 'batch_normalization_82/beta:0', 'batch_normalization_83/beta:0', 'conv2d_84/kernel:0', 'batch_normalization_76/beta:0', 'batch_normalization_84/beta:0', 'conv2d_89/kernel:0', 'batch_normalization_89/beta:0', 'conv2d_86/kernel:0', 'conv2d_90/kernel:0', 'batch_normalization_86/beta:0', 'batch_normalization_90/beta:0', 'conv2d_87/kernel:0', 'conv2d_88/kernel:0', 'conv2d_91/kernel:0', 'conv2d_92/kernel:0', 'conv2d_85/kernel:0', 'batch_normalization_87/beta:0', 'batch_normalization_88/beta:0', 'batch_normalization_91/beta:0', 'batch_normalization_92/beta:0', 'conv2d_93/kernel:0', 'batch_normalization_85/beta:0', 'batch_normalization_93/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0']."
     ]
    }
   ],
   "source": [
    "optimizer.apply_gradients(zip(grads, triplet_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE LOSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = new_dir + 'loss/'\n",
    "with open( results_dir + 'train_loss_plot{}.pkl'.format(n_samples), 'wb') as f:\n",
    "    pickle.dump(train_loss_plot, f)\n",
    "    \n",
    "with open( results_dir+ 'val_loss_plot{}.pkl'.format(n_samples), 'wb') as f:\n",
    "    pickle.dump(val_loss_plot, f)\n",
    "    \n",
    "with open(results_dir+ 'val_loss_history{}.pkl'.format(n_samples), 'wb') as f:\n",
    "    pickle.dump(val_loss_history, f)\n",
    "    \n",
    "with open(results_dir+ 'train_loss_history{}.pkl'.format(n_samples), 'wb') as f:\n",
    "    pickle.dump(loss_history, f)\n",
    "\n",
    "results_dir = new_dir + 'saved_models/'\n",
    "text_model.save(results_dir+'text_model_train_{}.h5'.format(n_samples))  # creates a HDF5 file 'my_model.h5'\n",
    "image_model.save(results_dir+'image_model_train_{}.h5'.format(n_samples))  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "\n",
    "text_model.save_weights(results_dir+'text_model_train_{}.h5'.format(n_samples))\n",
    "image_model.save_weights(results_dir+'image_model_train_{}.h5'.format(n_samples))\n",
    "triplet_model.save_weights(results_dir+'triplet_model_train_{}.h5'.format(n_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loss_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiaze Test Set after training model retrieving a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/src/train_790/objects/'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 600)               307800    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 600)               0         \n",
      "=================================================================\n",
      "Total params: 307,800\n",
      "Trainable params: 307,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 240, 240, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 119, 119, 32) 864         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchN (None, 119, 119, 32) 96          conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_564 (Activation)     (None, 119, 119, 32) 0           batch_normalization_564[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 117, 117, 32) 9216        activation_564[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_565 (BatchN (None, 117, 117, 32) 96          conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_565 (Activation)     (None, 117, 117, 32) 0           batch_normalization_565[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 117, 117, 64) 18432       activation_565[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_566 (BatchN (None, 117, 117, 64) 192         conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_566 (Activation)     (None, 117, 117, 64) 0           batch_normalization_566[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 58, 58, 64)   0           activation_566[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 58, 58, 80)   5120        max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchN (None, 58, 58, 80)   240         conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_567 (Activation)     (None, 58, 58, 80)   0           batch_normalization_567[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 56, 56, 192)  138240      activation_567[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchN (None, 56, 56, 192)  576         conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_568 (Activation)     (None, 56, 56, 192)  0           batch_normalization_568[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 27, 27, 192)  0           activation_568[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 27, 27, 64)   12288       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchN (None, 27, 27, 64)   192         conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_572 (Activation)     (None, 27, 27, 64)   0           batch_normalization_572[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 27, 27, 48)   9216        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 27, 27, 96)   55296       activation_572[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchN (None, 27, 27, 48)   144         conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchN (None, 27, 27, 96)   288         conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_570 (Activation)     (None, 27, 27, 48)   0           batch_normalization_570[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_573 (Activation)     (None, 27, 27, 96)   0           batch_normalization_573[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_54 (AveragePo (None, 27, 27, 192)  0           max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 27, 27, 64)   12288       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 27, 27, 64)   76800       activation_570[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 27, 27, 96)   82944       activation_573[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 27, 27, 32)   6144        average_pooling2d_54[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchN (None, 27, 27, 64)   192         conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchN (None, 27, 27, 64)   192         conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchN (None, 27, 27, 96)   288         conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchN (None, 27, 27, 32)   96          conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_569 (Activation)     (None, 27, 27, 64)   0           batch_normalization_569[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_571 (Activation)     (None, 27, 27, 64)   0           batch_normalization_571[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_574 (Activation)     (None, 27, 27, 96)   0           batch_normalization_574[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_575 (Activation)     (None, 27, 27, 32)   0           batch_normalization_575[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 27, 27, 256)  0           activation_569[0][0]             \n",
      "                                                                 activation_571[0][0]             \n",
      "                                                                 activation_574[0][0]             \n",
      "                                                                 activation_575[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 27, 27, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchN (None, 27, 27, 64)   192         conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_579 (Activation)     (None, 27, 27, 64)   0           batch_normalization_579[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 27, 27, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 27, 27, 96)   55296       activation_579[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchN (None, 27, 27, 48)   144         conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchN (None, 27, 27, 96)   288         conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_577 (Activation)     (None, 27, 27, 48)   0           batch_normalization_577[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_580 (Activation)     (None, 27, 27, 96)   0           batch_normalization_580[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_55 (AveragePo (None, 27, 27, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 27, 27, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 27, 27, 64)   76800       activation_577[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 27, 27, 96)   82944       activation_580[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 27, 27, 64)   16384       average_pooling2d_55[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchN (None, 27, 27, 64)   192         conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchN (None, 27, 27, 64)   192         conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchN (None, 27, 27, 96)   288         conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchN (None, 27, 27, 64)   192         conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_576 (Activation)     (None, 27, 27, 64)   0           batch_normalization_576[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_578 (Activation)     (None, 27, 27, 64)   0           batch_normalization_578[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_581 (Activation)     (None, 27, 27, 96)   0           batch_normalization_581[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_582 (Activation)     (None, 27, 27, 64)   0           batch_normalization_582[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 27, 27, 288)  0           activation_576[0][0]             \n",
      "                                                                 activation_578[0][0]             \n",
      "                                                                 activation_581[0][0]             \n",
      "                                                                 activation_582[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 27, 27, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 27, 27, 64)   192         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 27, 27, 64)   0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 27, 27, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 27, 27, 96)   55296       activation_586[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 27, 27, 48)   144         conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 27, 27, 96)   288         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 27, 27, 48)   0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 27, 27, 96)   0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_56 (AveragePo (None, 27, 27, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 27, 27, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 27, 27, 64)   76800       activation_584[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 27, 27, 96)   82944       activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 27, 27, 64)   18432       average_pooling2d_56[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchN (None, 27, 27, 64)   192         conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 27, 27, 64)   192         conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 27, 27, 96)   288         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 27, 27, 64)   192         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 27, 27, 64)   0           batch_normalization_583[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 27, 27, 64)   0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 27, 27, 96)   0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 27, 27, 64)   0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 27, 27, 288)  0           activation_583[0][0]             \n",
      "                                                                 activation_585[0][0]             \n",
      "                                                                 activation_588[0][0]             \n",
      "                                                                 activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 27, 27, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 27, 27, 64)   192         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_591 (Activation)     (None, 27, 27, 64)   0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 27, 27, 96)   55296       activation_591[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 27, 27, 96)   288         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_592 (Activation)     (None, 27, 27, 96)   0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 13, 13, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 13, 13, 96)   82944       activation_592[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 13, 13, 384)  1152        conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 13, 13, 96)   288         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 13, 13, 384)  0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_593 (Activation)     (None, 13, 13, 96)   0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 13, 13, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 13, 13, 768)  0           activation_590[0][0]             \n",
      "                                                                 activation_593[0][0]             \n",
      "                                                                 max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 13, 13, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 13, 13, 128)  384         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 13, 13, 128)  0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 13, 13, 128)  114688      activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 13, 13, 128)  384         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 13, 13, 128)  0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 13, 13, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 13, 13, 128)  114688      activation_599[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 13, 13, 128)  384         conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 13, 13, 128)  384         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_595 (Activation)     (None, 13, 13, 128)  0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 13, 13, 128)  0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 13, 13, 128)  114688      activation_595[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 13, 13, 128)  114688      activation_600[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 13, 13, 128)  384         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 13, 13, 128)  384         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 13, 13, 128)  0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 13, 13, 128)  0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_57 (AveragePo (None, 13, 13, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 13, 13, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 13, 13, 192)  172032      activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 13, 13, 192)  172032      activation_601[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 13, 13, 192)  147456      average_pooling2d_57[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 13, 13, 192)  576         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 13, 13, 192)  576         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 13, 13, 192)  576         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 13, 13, 192)  576         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_594 (Activation)     (None, 13, 13, 192)  0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 13, 13, 192)  0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 13, 13, 192)  0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 13, 13, 192)  0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 13, 13, 768)  0           activation_594[0][0]             \n",
      "                                                                 activation_597[0][0]             \n",
      "                                                                 activation_602[0][0]             \n",
      "                                                                 activation_603[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 13, 13, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 13, 13, 160)  480         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 13, 13, 160)  0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 13, 13, 160)  179200      activation_608[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 13, 13, 160)  480         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 13, 13, 160)  0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 13, 13, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 13, 13, 160)  179200      activation_609[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 13, 13, 160)  480         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 13, 13, 160)  480         conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 13, 13, 160)  0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 13, 13, 160)  0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 13, 13, 160)  179200      activation_605[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 13, 13, 160)  179200      activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 13, 13, 160)  480         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 13, 13, 160)  480         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 13, 13, 160)  0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 13, 13, 160)  0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_58 (AveragePo (None, 13, 13, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 13, 13, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 13, 13, 192)  215040      activation_606[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 13, 13, 192)  215040      activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 13, 13, 192)  147456      average_pooling2d_58[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 13, 13, 192)  576         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 13, 13, 192)  576         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 13, 13, 192)  576         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 13, 13, 192)  576         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 13, 13, 192)  0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 13, 13, 192)  0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 13, 13, 192)  0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 13, 13, 192)  0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 13, 13, 768)  0           activation_604[0][0]             \n",
      "                                                                 activation_607[0][0]             \n",
      "                                                                 activation_612[0][0]             \n",
      "                                                                 activation_613[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 13, 13, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 13, 13, 160)  480         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 13, 13, 160)  0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 13, 13, 160)  179200      activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 13, 13, 160)  480         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 13, 13, 160)  0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 13, 13, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 13, 13, 160)  179200      activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 13, 13, 160)  480         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 13, 13, 160)  480         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 13, 13, 160)  0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 13, 13, 160)  0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 13, 13, 160)  179200      activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 13, 13, 160)  179200      activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 13, 13, 160)  480         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 13, 13, 160)  480         conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 13, 13, 160)  0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 13, 13, 160)  0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_59 (AveragePo (None, 13, 13, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 13, 13, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 13, 13, 192)  215040      activation_616[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 13, 13, 192)  215040      activation_621[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 13, 13, 192)  147456      average_pooling2d_59[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 13, 13, 192)  576         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 13, 13, 192)  576         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 13, 13, 192)  576         conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 13, 13, 192)  576         conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 13, 13, 192)  0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 13, 13, 192)  0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 13, 13, 192)  0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 13, 13, 192)  0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 13, 13, 768)  0           activation_614[0][0]             \n",
      "                                                                 activation_617[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "                                                                 activation_623[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 13, 13, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 13, 13, 192)  576         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 13, 13, 192)  0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 13, 13, 192)  258048      activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 13, 13, 192)  576         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 13, 13, 192)  0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 13, 13, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 13, 13, 192)  258048      activation_629[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 13, 13, 192)  576         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 13, 13, 192)  576         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 13, 13, 192)  0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 13, 13, 192)  0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 13, 13, 192)  258048      activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 13, 13, 192)  258048      activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 13, 13, 192)  576         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 13, 13, 192)  576         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 13, 13, 192)  0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 13, 13, 192)  0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePo (None, 13, 13, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 13, 13, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 13, 13, 192)  258048      activation_626[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 13, 13, 192)  258048      activation_631[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 13, 13, 192)  147456      average_pooling2d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 13, 13, 192)  576         conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 13, 13, 192)  576         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 13, 13, 192)  576         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 13, 13, 192)  576         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 13, 13, 192)  0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 13, 13, 192)  0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 13, 13, 192)  0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 13, 13, 192)  0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 13, 13, 768)  0           activation_624[0][0]             \n",
      "                                                                 activation_627[0][0]             \n",
      "                                                                 activation_632[0][0]             \n",
      "                                                                 activation_633[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 13, 13, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 13, 13, 192)  576         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 13, 13, 192)  0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 13, 13, 192)  258048      activation_636[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 13, 13, 192)  576         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 13, 13, 192)  0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 13, 13, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 13, 13, 192)  258048      activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 13, 13, 192)  576         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 13, 13, 192)  576         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 13, 13, 192)  0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 13, 13, 192)  0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 6, 6, 320)    552960      activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 6, 6, 192)    331776      activation_638[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 6, 6, 320)    960         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 6, 6, 192)    576         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 6, 6, 320)    0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 6, 6, 192)    0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_635[0][0]             \n",
      "                                                                 activation_639[0][0]             \n",
      "                                                                 max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 6, 6, 448)    1344        conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 6, 6, 448)    0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 6, 6, 384)    1548288     activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 6, 6, 384)    1152        conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 6, 6, 384)    1152        conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 6, 6, 384)    0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 6, 6, 384)    0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 6, 6, 384)    442368      activation_641[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 6, 6, 384)    442368      activation_641[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 6, 6, 384)    442368      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 6, 6, 384)    442368      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 6, 6, 384)    1152        conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 6, 6, 384)    1152        conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 6, 6, 384)    1152        conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 6, 6, 384)    1152        conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 6, 6, 192)    245760      average_pooling2d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 6, 6, 320)    960         conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 6, 6, 384)    0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 6, 6, 384)    0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 6, 6, 384)    0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 6, 6, 384)    0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 6, 6, 192)    576         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 6, 6, 320)    0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_642[0][0]             \n",
      "                                                                 activation_643[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 6, 6, 768)    0           activation_646[0][0]             \n",
      "                                                                 activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 6, 6, 192)    0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_640[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 6, 6, 448)    1344        conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 6, 6, 448)    0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 6, 6, 384)    1548288     activation_653[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 6, 6, 384)    1152        conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 6, 6, 384)    1152        conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 6, 6, 384)    0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 6, 6, 384)    0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 6, 6, 384)    442368      activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 6, 6, 384)    442368      activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 6, 6, 384)    442368      activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 6, 6, 384)    442368      activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 6, 6, 384)    1152        conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 6, 6, 384)    1152        conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 6, 6, 384)    1152        conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 6, 6, 384)    1152        conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 6, 6, 192)    393216      average_pooling2d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 6, 6, 320)    960         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 6, 6, 384)    0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 6, 6, 384)    0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_655 (Activation)     (None, 6, 6, 384)    0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_656 (Activation)     (None, 6, 6, 384)    0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 6, 6, 192)    576         conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 6, 6, 320)    0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_651[0][0]             \n",
      "                                                                 activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 6, 6, 768)    0           activation_655[0][0]             \n",
      "                                                                 activation_656[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_657 (Activation)     (None, 6, 6, 192)    0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_649[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 activation_657[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 600)          1229400     global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 600)          0           dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,032,184\n",
      "Trainable params: 22,997,752\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### LOADING from saved_weights (correct)\n",
    "new_dir = \"/data/src/train_{}/\".format(n_samples)\n",
    "results_dir = new_dir + 'saved_models/'\n",
    "\n",
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    text_model = glove_lstm_atten(EMBEDDING_DIM, SHARED_EMBEDDING_DIM)\n",
    "    image_model = image_inceptionv3_model(IMG_SHAPE, SHARED_EMBEDDING_DIM)\n",
    "\n",
    "text_model.save_weights(results_dir+'text_model_train_{}.h5'.format(n_samples))\n",
    "image_model.save_weights(results_dir+'image_model_train_{}.h5'.format(n_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test size: 158 \n",
      "train size: 422 \n",
      "validation size: 210\n"
     ]
    }
   ],
   "source": [
    "path = '/data/src/train_{}/objects/'.format(n_samples)  # new_dir + 'train_7120759/'\n",
    "path = os.path.join(path)\n",
    "with open(path+ 'list_IDs{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs = pickle.load(f) \n",
    "with open(path+ 'list_IDs_test{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs_test = pickle.load(f) \n",
    "with open(path+ 'list_IDs_val{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs_val = pickle.load(f) \n",
    "with open(path+ 'list_IDs_train{}.pkl'.format(n_samples), 'rb') as f:\n",
    "    list_IDs_train = pickle.load(f)\n",
    "\n",
    "print('\\ntest size:',len(list_IDs_test), \n",
    "      '\\ntrain size:', len(list_IDs_train), \n",
    "      '\\nvalidation size:', len(list_IDs_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\u7523\\u696d\\u6a5f\\u5668\\u3000\\u30e2\\u30fc\\u30bf\\u30fc'    1\n",
       "u'facebook'                                                  1\n",
       "u'branches clip'                                             1\n",
       "u'Love books'                                                1\n",
       "u'belgie'                                                    1\n",
       "                                                            ..\n",
       "u'new product'                                               1\n",
       "u'live news'                                                 1\n",
       "u'remote team'                                               1\n",
       "u'wellbeing'                                                 1\n",
       "u'hockey poster'                                             1\n",
       "Name: query, Length: 158, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sampled_train.iloc[list_IDs_test] # get test set rows\n",
    "freq_count = df['query'].value_counts()\n",
    "freq_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<BatchDataset shapes: (None, 512), types: tf.float32>,\n",
       " <BatchDataset shapes: (None, 240, 240, 3), types: tf.float32>,\n",
       " <BatchDataset shapes: (None, 240, 240, 3), types: tf.float32>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vis_batch = 1\n",
    "sample_pos_img_dataset = tf.data.Dataset.from_tensor_slices(p_)\n",
    "sample_pos_img_dataset = sample_pos_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(vis_batch)\n",
    "\n",
    "sample_neg_img_dataset = tf.data.Dataset.from_tensor_slices(n_)\n",
    "sample_neg_img_dataset = sample_neg_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(vis_batch)\n",
    "\n",
    "sample_position_bias_dataset = tf.data.Dataset.from_generator(lambda: gen_series(pb_), output_types=(tf.float32),output_shapes = ( ())) # if set it (1,) -> ValueError: `generator` yielded an element of shape () where an element of shape (1,) was expected\n",
    "sample_position_bias_dataset = sample_position_bias_dataset.batch(vis_batch)\n",
    "\n",
    "sample_query_dataset = tf.data.Dataset.from_generator(lambda: embed_model(q_), \n",
    "                                                          output_types=(tf.float32), \n",
    "                                                          output_shapes=( ( EMBEDDING_DIM)))\n",
    "\n",
    "\n",
    "\n",
    "sample_query_dataset = sample_query_dataset.batch(vis_batch)\n",
    "\n",
    "sample_query_dataset, sample_neg_img_dataset, sample_pos_img_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-1ebec2aa13d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mq_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mlist_IDs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get query test associated with this query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mlist_IDs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_img_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mlist_IDs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_img_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "q_test = list(itemgetter(* list_IDs_test)(query_seqs)) #get query test associated with this query\n",
    "p_test = list(itemgetter(* list_IDs_test)(p_img_paths))\n",
    "n_test = list(itemgetter(* list_IDs_test)(n_img_paths))\n",
    "pb_test = list(itemgetter(* list_IDs_test)(position_bias))\n",
    "\n",
    "print(len(q_test), len(p_test), len(n_test), len(pb_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30749, 153745, 785)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_IDs_test), len(n_img_paths), len(query_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in test set with size 157, there are 2 number of queries with text poster\n"
     ]
    }
   ],
   "source": [
    "query = 'poster'\n",
    "embed_model([query])\n",
    "list_of_indices = np.flatnonzero( df['query'].apply(lambda x: x.strip('u').strip('\\''))  == query)\n",
    "print(\"in test set with size {}, there are {} number of queries with text {}\".format(len(df), len(list_of_indices), query ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "q_ = list(itemgetter(* list_of_indices)(q_test)) #get query test associated with this query\n",
    "p_ = list(itemgetter(* list_of_indices)(p_test))\n",
    "n_ = list(itemgetter(* list_of_indices)(n_test))\n",
    "pb_ = list(itemgetter(* list_of_indices)(pb_test))\n",
    "query_size = len(list_of_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u'earth'\",\n",
       " \"u'feuille'\",\n",
       " \"u'moon'\",\n",
       " \"u'healthy smile'\",\n",
       " \"u'hay field'\",\n",
       " \"u'herz ballon'\",\n",
       " \"u'soil'\",\n",
       " \"u'mental energy'\",\n",
       " \"u'\\\\u30c6\\\\u30ec\\\\u30d3'\",\n",
       " \"u'sunset'\",\n",
       " \"u'rouw'\",\n",
       " \"u'roll up'\",\n",
       " \"u'denver city'\",\n",
       " \"u'coffee teeth'\",\n",
       " \"u'd\\\\xe9coration blanche'\",\n",
       " \"u'\\\\u5e03\\\\u3000\\\\u30c6\\\\u30af\\\\u30b9\\\\u30c1\\\\u30e3'\",\n",
       " \"u'Mograph'\",\n",
       " \"u'corona virus icon'\",\n",
       " \"u'indesign'\",\n",
       " \"u'infographic icon'\",\n",
       " \"u'senior at home illustration'\",\n",
       " \"u'Salt crystals in bowl white background'\",\n",
       " \"u'Stadtplan New york'\",\n",
       " \"u'THC MOLECULE'\",\n",
       " \"u'skull and crossbones'\",\n",
       " \"u'led lights people'\",\n",
       " \"u'champagne'\",\n",
       " \"u'tight rope'\",\n",
       " \"u'pitch'\",\n",
       " \"u'figure skating graphics'\",\n",
       " \"u'nuclear fallout background'\",\n",
       " \"u'weinbau'\",\n",
       " \"u'man hold'\",\n",
       " \"u'surprised angry'\",\n",
       " \"u'cat eating white'\",\n",
       " \"u'rustic sketch leaves'\",\n",
       " \"u'wine cheers'\",\n",
       " \"u'london soho'\",\n",
       " \"u'\\\\u767d\\\\u3000\\\\u82b1'\",\n",
       " \"u'quote'\",\n",
       " \"u'rustic background wooden planks'\",\n",
       " \"u'games'\",\n",
       " \"u'christmas dinner banner'\",\n",
       " \"u'business innovation'\",\n",
       " \"u'birnen'\",\n",
       " \"u'project timeline'\",\n",
       " \"u'midsommar'\",\n",
       " \"u'north carolina'\",\n",
       " \"u'thyroid'\",\n",
       " \"u'streaming movie couch'\",\n",
       " \"u'skid steer in snow'\",\n",
       " \"u'\\\\u90f5\\\\u4fbf'\",\n",
       " \"u'blue'\",\n",
       " \"u'agency real estate'\",\n",
       " \"u'information technology'\",\n",
       " \"u'\\\\u30dd\\\\u30c3\\\\u30d7\\\\u3000\\\\u30dd\\\\u30b9\\\\u30bf\\\\u30fc\\\\u3000ICON'\",\n",
       " \"u'grill fish'\",\n",
       " \"u'social studies'\",\n",
       " \"u'golf flyer'\",\n",
       " \"u'vector hand phone'\",\n",
       " \"u'moon rock vector'\",\n",
       " \"u'cancer'\",\n",
       " \"u'spirituosen'\",\n",
       " \"u'kids handwashing'\",\n",
       " \"u'cs logo'\",\n",
       " \"u'sustainability icons'\",\n",
       " \"u'fire extinguisher'\",\n",
       " \"u'man in office'\",\n",
       " \"u'running icon'\",\n",
       " \"u'construction site'\",\n",
       " \"u'cabelo cacheado'\",\n",
       " \"u'ch\\\\u0142opak dziewczyna background'\",\n",
       " \"u'Sports car image'\",\n",
       " \"u'rock'\",\n",
       " \"u'film news'\",\n",
       " \"u'euro schein hand'\",\n",
       " \"u'business color'\",\n",
       " \"u'\\\\u5352\\\\u696d\\\\u3000\\\\u6587\\\\u5b57'\",\n",
       " \"u'hartford connecticut'\",\n",
       " \"u'olive tree'\",\n",
       " \"u'chicago'\",\n",
       " \"u'travel businesses'\",\n",
       " \"u'social media'\",\n",
       " \"u'cooking'\",\n",
       " \"u'thank you'\",\n",
       " \"u'lime green vector'\",\n",
       " \"u'\\\\u5185\\\\u81d3'\",\n",
       " \"u'family in new home'\",\n",
       " \"u'pizza baking'\",\n",
       " \"u'comic'\",\n",
       " \"u'happy people working'\",\n",
       " \"u'presentation'\",\n",
       " \"u'workshop'\",\n",
       " \"u'mockup booth'\",\n",
       " \"u'presentation'\",\n",
       " \"u'bunny sketches'\",\n",
       " \"u'water bottle icon'\",\n",
       " \"u'picture frame'\",\n",
       " \"u'one women'\",\n",
       " \"u'video'\",\n",
       " \"u'abstract background light'\",\n",
       " \"u'formation s\\\\xe9curit\\\\xe9 au travail'\",\n",
       " \"u'doctor data'\",\n",
       " \"u'child therapy'\",\n",
       " \"u'diamond'\",\n",
       " \"u'\\\\u733f'\",\n",
       " \"u'trabajadores'\",\n",
       " \"u'juice'\",\n",
       " \"u'checkout ecommerce'\",\n",
       " \"u'pixel'\",\n",
       " \"u'dry ice'\",\n",
       " \"u'\\\\u5e74\\\\u8cc0'\",\n",
       " \"u'christmas frame'\",\n",
       " \"u'inch ruler'\",\n",
       " \"u'ostern'\",\n",
       " \"u'dog holding sign'\",\n",
       " \"u'pizza top view'\",\n",
       " \"u'women flowers'\",\n",
       " \"u'competition'\",\n",
       " \"u'clothes box woman'\",\n",
       " \"u'measurement'\",\n",
       " \"u'theater for kids'\",\n",
       " \"u'Pfad'\",\n",
       " \"u'presentaciones'\",\n",
       " \"u'CAULIFLOWER RICE'\",\n",
       " \"u'exercise background'\",\n",
       " \"u'sun ray'\",\n",
       " \"u'tax'\",\n",
       " \"u'arrow'\",\n",
       " \"u'christmas forrest'\",\n",
       " \"u'dna line'\",\n",
       " \"u'\\\\xe9l\\\\xe9phant afrique'\",\n",
       " \"u'fitness'\",\n",
       " \"u'jigsaw'\",\n",
       " \"u'selfie on white'\",\n",
       " \"u'lapiz feliz'\",\n",
       " \"u'sustainable design'\",\n",
       " \"u'closed'\",\n",
       " \"u'sexy couple'\",\n",
       " \"u'defamation'\",\n",
       " \"u'fahrer auto'\",\n",
       " \"u'kids background'\",\n",
       " \"u'burst'\",\n",
       " \"u'Landscape'\",\n",
       " \"u'ni\\\\xf1o sonrisa'\",\n",
       " \"u'muscle car'\",\n",
       " \"u'soup'\",\n",
       " \"u'podcast vector'\",\n",
       " \"u'lung cancer'\",\n",
       " \"u'corona distance'\",\n",
       " \"u'sleep well'\",\n",
       " \"u'world map vector'\",\n",
       " \"u'snow'\",\n",
       " \"u'garant\\\\xeda'\",\n",
       " \"u'wirus lekarz zwyci\\\\u0119stwo'\",\n",
       " \"u'beer tasting'\",\n",
       " \"u'icon free'\",\n",
       " \"u'group black women'\",\n",
       " \"u'audio tape icon'\",\n",
       " \"u'allume feu sac'\",\n",
       " \"u'schritte'\",\n",
       " \"u'hintergrund blau eckig'\",\n",
       " \"u'cannabis'\",\n",
       " \"u'mobile'\",\n",
       " \"u'nouvel an'\",\n",
       " \"u'walk to school'\",\n",
       " \"u'happy man'\",\n",
       " \"u'welle tropfen'\",\n",
       " \"u'gears'\",\n",
       " \"u'steam'\",\n",
       " \"u'Linie'\",\n",
       " \"u'doctor team'\",\n",
       " \"u'farmaceutica'\",\n",
       " \"u'mousse ricotta e cioccolato'\",\n",
       " \"u'march\\\\xe9 alimentaire'\",\n",
       " \"u'servant'\",\n",
       " \"u'bathroom'\",\n",
       " \"u'shopping cart'\",\n",
       " \"u'ac system'\",\n",
       " \"u'witch pattern vector'\",\n",
       " \"u'conference poster business'\",\n",
       " \"u'burguer'\",\n",
       " \"u'children'\",\n",
       " \"u'wine red'\",\n",
       " \"u'grow business'\",\n",
       " \"u'ice water glass'\",\n",
       " \"u'cup of tea COPYSPACE'\",\n",
       " \"u'purple confetti background'\",\n",
       " \"u'hallway school'\",\n",
       " \"u'credit report'\",\n",
       " \"u'8'\",\n",
       " \"u'interior'\",\n",
       " \"u'constellation zodiac'\",\n",
       " \"u'social media logos'\",\n",
       " \"u'poster'\",\n",
       " \"u'WOOD'\",\n",
       " \"u'soil scoop'\",\n",
       " \"u'rugby CHILDREN'\",\n",
       " \"u'office mockup desk'\",\n",
       " \"u'january'\",\n",
       " \"u'd\\\\xfcsseldorf'\",\n",
       " \"u'succo icona'\",\n",
       " \"u'news background'\",\n",
       " \"u'judias verdes'\",\n",
       " \"u'feet up on a beach'\",\n",
       " \"u'psoas'\",\n",
       " \"u'sonnenaufgang illustration'\",\n",
       " \"u'sand bucket shovel watercolor'\",\n",
       " \"u'invitation'\",\n",
       " \"u'City building models 3D'\",\n",
       " \"u'face mask'\",\n",
       " \"u'wind vector'\",\n",
       " \"u'black woman stop'\",\n",
       " \"u'words letters'\",\n",
       " \"u'old homes'\",\n",
       " \"u'genie lamp'\",\n",
       " \"u'flat sock'\",\n",
       " \"u'ararat'\",\n",
       " \"u'coronavirus'\",\n",
       " \"u'winter car'\",\n",
       " \"u'quito ecuador'\",\n",
       " \"u'anime eyes'\",\n",
       " \"u'leaf wind'\",\n",
       " \"u'snow background'\",\n",
       " \"u'brama kute'\",\n",
       " \"u'chef cooking'\",\n",
       " \"u'scared'\",\n",
       " \"u'twitter'\",\n",
       " \"u'concrete texture'\",\n",
       " \"u'snow-white'\",\n",
       " \"u'archer'\",\n",
       " \"u'engagement in the workplace'\",\n",
       " \"u'forge'\",\n",
       " \"u'emojis'\",\n",
       " \"u'taureau flat design'\",\n",
       " \"u'bangkok city night'\",\n",
       " \"u'calligraphy fonts'\",\n",
       " \"u'hand'\",\n",
       " \"u'human body'\",\n",
       " \"u'certificate'\",\n",
       " \"u'love is love'\",\n",
       " \"u'pozna\\\\u0144'\",\n",
       " \"u'fire'\",\n",
       " \"u'nature'\",\n",
       " \"u'chandelier flame'\",\n",
       " \"u'vase of flowers'\",\n",
       " \"u'blue tea'\",\n",
       " \"u'T\\\\u30b7\\\\u30e3\\\\u30c4'\",\n",
       " \"u'breast cancer ribbon'\",\n",
       " \"u'workplace'\",\n",
       " \"u'wine'\",\n",
       " \"u'game button'\",\n",
       " \"u'frame mockup'\",\n",
       " \"u'sydney'\",\n",
       " \"u'spa pool'\",\n",
       " \"u'semi'\",\n",
       " \"u'pen'\",\n",
       " \"u'emoji'\",\n",
       " \"u'iconos electricidad'\",\n",
       " \"u'TELEPHONE'\",\n",
       " \"u'budget infographic'\",\n",
       " \"u'carrots'\",\n",
       " \"u'\\\\u8349\\\\u539f'\",\n",
       " \"u'percentages'\",\n",
       " \"u'smoke'\",\n",
       " \"u'Q&A'\",\n",
       " \"u'infographic'\",\n",
       " \"u'icon line risk'\",\n",
       " \"u'nose job'\",\n",
       " \"u'phone icon vector'\",\n",
       " \"u'office background'\",\n",
       " \"u'advertise'\",\n",
       " \"u'physiotherapy'\",\n",
       " \"u'artificial intelligence'\",\n",
       " \"u'fr\\\\xfchling'\",\n",
       " \"u'las vegas'\",\n",
       " \"u'people silhouette'\",\n",
       " \"u'smoke overlay'\",\n",
       " \"u'train interior cartoon'\",\n",
       " \"u'shapes'\",\n",
       " \"u'\\\\u66f8\\\\u985e\\\\u3000\\\\u5927\\\\u91cf'\",\n",
       " \"u'customer happy'\",\n",
       " \"u'LOISIRS DE PRINTEMPS'\",\n",
       " \"u'thanksgiving family'\",\n",
       " \"u'typography'\",\n",
       " \"u'Power icon'\",\n",
       " \"u'happy thanksgiving'\",\n",
       " \"u'video game addiction'\",\n",
       " \"u'nikolausstiefel'\",\n",
       " \"u'fridges'\",\n",
       " \"u'2020 road'\",\n",
       " \"u'made in germany'\",\n",
       " \"u'I logo'\",\n",
       " \"u'reisen grafik'\",\n",
       " \"u'cbd'\",\n",
       " \"u'december icon'\",\n",
       " \"u'risotto'\",\n",
       " \"u'play button'\",\n",
       " \"u'3d takeout'\",\n",
       " \"u'\\\\u30ab\\\\u30ec\\\\u30f3\\\\u30c0\\\\u30fc\\\\u30002019\\\\u5e74\\\\u30002020\\\\u5e74'\",\n",
       " \"u'package texture'\",\n",
       " \"u'traditional italian pizza'\",\n",
       " \"u'taco'\",\n",
       " \"u'fruit'\",\n",
       " \"u'produit frais'\",\n",
       " \"u'ostern frohe'\",\n",
       " \"u'Malaysia'\",\n",
       " \"u'mobile design'\",\n",
       " \"u'sejf \\\\u015bciana'\",\n",
       " \"u'IPAD'\",\n",
       " \"u'barn owl'\",\n",
       " \"u'munt euro'\",\n",
       " \"u'animation storyboard'\",\n",
       " \"u'ziele'\",\n",
       " \"u'flourish'\",\n",
       " \"u'\\\\u672d\\\\u3000\\\\u6728'\",\n",
       " \"u'Screen texture vector'\",\n",
       " \"u'broccoli leafy'\",\n",
       " \"u'pub textures'\",\n",
       " \"u'concrete texture'\",\n",
       " \"u'icon set'\",\n",
       " \"u'col\\\\xe8re au travail'\",\n",
       " \"u'picto dossier'\",\n",
       " \"u'ticket icon'\",\n",
       " \"u'holy spirit'\",\n",
       " \"u'blue zigzag stripes'\",\n",
       " \"u'baseball bat'\",\n",
       " \"u'diabetes'\",\n",
       " \"u'heart tree'\",\n",
       " \"u'remodel'\",\n",
       " \"u'basketball'\",\n",
       " \"u'rose'\",\n",
       " \"u'ESG'\",\n",
       " \"u'pin cushion'\",\n",
       " \"u'kugeln gold'\",\n",
       " \"u'Wild life'\",\n",
       " \"u'easter'\",\n",
       " \"u'talking on cans'\",\n",
       " \"u'south african flag'\",\n",
       " \"u'ice cream biscuit'\",\n",
       " \"u'headphones'\",\n",
       " \"u'essen frankreich'\",\n",
       " \"u'party balloons'\",\n",
       " \"u'crisis housing'\",\n",
       " \"u'UAE national day'\",\n",
       " \"u'strand'\",\n",
       " \"u'\\\\u30b4\\\\u30fc\\\\u30eb\\\\u30c9\\\\u3000\\\\u30c6\\\\u30af\\\\u30b9\\\\u30c1\\\\u30e3'\",\n",
       " \"u'mountains'\",\n",
       " \"u'office Party'\",\n",
       " \"u'apple tree'\",\n",
       " \"u'canarias'\",\n",
       " \"u'\\\\u0431\\\\u0430\\\\u043d\\\\u0442 \\\\u0432\\\\u0435\\\\u043a\\\\u0442\\\\u043e\\\\u0440'\",\n",
       " \"u'thank you'\",\n",
       " \"u'paper'\",\n",
       " \"u'easter'\",\n",
       " \"u'illustration writing'\",\n",
       " \"u'fire sparks'\",\n",
       " \"u'\\\\u8ddd\\\\u96e2\\\\u3000\\\\u30a2\\\\u30a4\\\\u30b3\\\\u30f3'\",\n",
       " \"u'Igel'\",\n",
       " \"u'scientist background vintage'\",\n",
       " \"u'leaves green with sunlight'\",\n",
       " \"u'training vector'\",\n",
       " \"u'bar and grill'\",\n",
       " \"u'ikony drzwi'\",\n",
       " \"u'Recycle'\",\n",
       " \"u'wedding menu'\",\n",
       " \"u'rechtsform unternehmen'\",\n",
       " \"u'flyer'\",\n",
       " \"u'shooting stars'\",\n",
       " \"u'arabic pattern'\",\n",
       " \"u'bee logo'\",\n",
       " \"u'Work from home'\",\n",
       " \"u'crocodile'\",\n",
       " \"u'autocar'\",\n",
       " \"u'ic\\\\xf4ne boisson'\",\n",
       " \"u'internship'\",\n",
       " \"u'encuesta'\",\n",
       " \"u'stockholm'\",\n",
       " \"u'schuften'\",\n",
       " \"u'festival'\",\n",
       " \"u'easter'\",\n",
       " \"u'debt collection'\",\n",
       " \"u'mock up softcover'\",\n",
       " \"u'vase'\",\n",
       " \"u'dancer'\",\n",
       " \"u'alaska'\",\n",
       " \"u'Cedro libanese'\",\n",
       " \"u'light burst'\",\n",
       " \"u'\\\\u30aa\\\\u30fc\\\\u30ed\\\\u30e9 \\\\u5357\\\\u6975'\",\n",
       " \"u'Steak sandwich'\",\n",
       " \"u'fake flamingoes'\",\n",
       " \"u'family kitchen'\",\n",
       " \"u'oregano'\",\n",
       " \"u'r\\\\xf4ti de porc'\",\n",
       " \"u'mixer'\",\n",
       " \"u'\\\\u7d19'\",\n",
       " \"u'cioccolato croissant'\",\n",
       " \"u'leaf'\",\n",
       " \"u'maple leaf'\",\n",
       " \"u'\\\\u81ea\\\\u52d5\\\\u8eca\\\\u4fee\\\\u7406'\",\n",
       " \"u'high school campus'\",\n",
       " \"u'soap'\",\n",
       " \"u'mumbai + vector'\",\n",
       " \"u'background green'\",\n",
       " \"u'vintage acoustic guitar'\",\n",
       " \"u'technology in agriculture'\",\n",
       " \"u'mexico country shapes'\",\n",
       " \"u'closet clothes'\",\n",
       " \"u'butter'\",\n",
       " \"u'powder'\",\n",
       " \"u'women investing'\",\n",
       " \"u'enfant'\",\n",
       " \"u'mandel muss'\",\n",
       " \"u'room empty'\",\n",
       " \"u'\\\\u30d6\\\\u30eb\\\\u30fc\\\\u3000\\\\u30a2\\\\u30fc\\\\u30c8'\",\n",
       " \"u'lavanderia disegni'\",\n",
       " \"u'peaches'\",\n",
       " \"u'parliament speech'\",\n",
       " \"u'virtual meeting wave'\",\n",
       " \"u'bra background'\",\n",
       " \"u'potrawa'\",\n",
       " \"u'plastic bottle'\",\n",
       " \"u'\\\\u30aa\\\\u30f3\\\\u30bf\\\\u30ea\\\\u30aa\\\\u5dde\\\\u3000\\\\u5730\\\\u56f3'\",\n",
       " \"u'truck driver'\",\n",
       " \"u'brush stroke'\",\n",
       " \"u'\\\\u9283 \\\\u30a4\\\\u30e9\\\\u30b9\\\\u30c8\\\\u75d5'\",\n",
       " \"u'star vintage'\",\n",
       " \"u'eye icon'\",\n",
       " \"u'job interview'\",\n",
       " \"u'stickers'\",\n",
       " \"u'real estate presentation'\",\n",
       " \"u'lemur'\",\n",
       " \"u'3d background'\",\n",
       " \"u'traffic light illustration'\",\n",
       " \"u'white background'\",\n",
       " \"u'\\\\u30d9\\\\u30c8\\\\u30ca\\\\u30e0'\",\n",
       " \"u'luxury property'\",\n",
       " \"u'isolated'\",\n",
       " \"u'd\\\\xe9grad\\\\xe9 bleu'\",\n",
       " \"u'childhood obesity'\",\n",
       " \"u'urgence'\",\n",
       " \"u'smoothie'\",\n",
       " \"u'PIMENT VUE DU HAUT'\",\n",
       " \"u'cured meat'\",\n",
       " \"u'travelling'\",\n",
       " \"u'car parts'\",\n",
       " \"u'horse'\",\n",
       " \"u'transport travaux'\",\n",
       " \"u'x doodle'\",\n",
       " \"u'Tagliatelle'\",\n",
       " \"u'business woman'\",\n",
       " \"u'eye doctor'\",\n",
       " \"u'christmas pet'\",\n",
       " \"u'vine vector'\",\n",
       " \"u'\\\\u4e5d\\\\u4efd'\",\n",
       " \"u'comicheld'\",\n",
       " \"u'roof'\",\n",
       " \"u'monopoly'\",\n",
       " \"u'television'\",\n",
       " \"u'hurry'\",\n",
       " \"u'hours icon'\",\n",
       " \"u'escaping death'\",\n",
       " \"u'station ski'\",\n",
       " \"u'bredband'\",\n",
       " \"u'antibacterial'\",\n",
       " \"u'palm tree'\",\n",
       " \"u'grass illustration'\",\n",
       " \"u'castle'\",\n",
       " \"u'grey backgrounds'\",\n",
       " \"u'like'\",\n",
       " \"u'poster'\",\n",
       " \"u'\\\\u30c6\\\\u30f3\\\\u30d7\\\\u30ec\\\\u30fc\\\\u30c8'\",\n",
       " \"u'edinburgh mystery'\",\n",
       " \"u'vector arrow'\",\n",
       " \"u'visualizations'\",\n",
       " \"u'trampoline'\",\n",
       " \"u'jubil\\\\xe4um'\",\n",
       " \"u'light texture'\",\n",
       " \"u'seatbelts icon'\",\n",
       " \"u'\\\\u8907\\\\u6570'\",\n",
       " \"u'paint booth'\",\n",
       " \"u'football'\",\n",
       " \"u'graduation 2019'\",\n",
       " \"u'4th of july'\",\n",
       " \"u'heating and air'\",\n",
       " \"u'brain'\",\n",
       " \"u'talk icon'\",\n",
       " \"u'sale'\",\n",
       " \"u'sign'\",\n",
       " \"u'ampoule picto'\",\n",
       " \"u'Nurses coffee'\",\n",
       " \"u'stetoskop'\",\n",
       " \"u'white texture'\",\n",
       " \"u'acupuntura'\",\n",
       " \"u'flowers garden'\",\n",
       " \"u'smart manufacturing'\",\n",
       " \"u'masque en tissu'\",\n",
       " \"u'self worth'\",\n",
       " \"u'astronaut moon'\",\n",
       " \"u'france'\",\n",
       " \"u'riso'\",\n",
       " \"u'money falling'\",\n",
       " \"u'memphis'\",\n",
       " \"u'fleur nature'\",\n",
       " \"u'kids sneakers skateboards'\",\n",
       " \"u'austin'\",\n",
       " \"u'mono lake'\",\n",
       " \"u'writer'\",\n",
       " \"u'school lunch room'\",\n",
       " \"u'CARBON FIBER'\",\n",
       " \"u'Urlaub'\",\n",
       " \"u'Law justice'\",\n",
       " \"u'sparkle ring'\",\n",
       " \"u'kitchen'\",\n",
       " \"u'anemone flower'\",\n",
       " \"u'arrow sketch'\",\n",
       " \"u'health technology icon'\",\n",
       " \"u'diamonds making'\",\n",
       " \"u'grunge'\",\n",
       " \"u'lawn care'\",\n",
       " \"u'house restoration'\",\n",
       " \"u'research icon'\",\n",
       " \"u'desk cleaning'\",\n",
       " \"u'bugnes'\",\n",
       " \"u'bubble bath'\",\n",
       " \"u'stethoscope illustrator'\",\n",
       " \"u'madera'\",\n",
       " \"u'instagram food'\",\n",
       " \"u'producteur locaux'\",\n",
       " \"u'funny lawyer'\",\n",
       " \"u'ivy'\",\n",
       " \"u'presentation'\",\n",
       " \"u'parc national de la rivi\\\\xe8re onkaparinga'\",\n",
       " \"u'robotic process automation'\",\n",
       " \"u'hammer'\",\n",
       " \"u'cornucopia'\",\n",
       " \"u'\\\\u6249'\",\n",
       " \"u'wood background'\",\n",
       " \"u'patients'\",\n",
       " \"u'stop'\",\n",
       " \"u'wireframe'\",\n",
       " \"u'document'\",\n",
       " \"u'boxe sac de frappe'\",\n",
       " \"u'thank you'\",\n",
       " \"u'jobless'\",\n",
       " \"u'green leaf falling'\",\n",
       " \"u'bierglas vektor'\",\n",
       " \"u'sun icon'\",\n",
       " \"u'leg moisturiser'\",\n",
       " \"u'red flare'\",\n",
       " \"u'jungle'\",\n",
       " \"u'chatbot'\",\n",
       " \"u'lawyer'\",\n",
       " \"u'ragweed'\",\n",
       " \"u'ornate line'\",\n",
       " \"u'flash'\",\n",
       " \"u'texas icon'\",\n",
       " \"u'butter'\",\n",
       " \"u'value'\",\n",
       " \"u'Fahrrad werkstatt'\",\n",
       " \"u'heart device'\",\n",
       " \"u'fireworks'\",\n",
       " \"u'matterhorn'\",\n",
       " \"u'spirit dove'\",\n",
       " \"u'cottonmouth'\",\n",
       " \"u'horse jumping'\",\n",
       " \"u'vektor baum'\",\n",
       " \"u'QR\\\\u30b3\\\\u30fc\\\\u30c9'\",\n",
       " \"u'infographic house'\",\n",
       " \"u'aloe vera'\",\n",
       " \"u'table top'\",\n",
       " \"u'Arbre moringa'\",\n",
       " \"u'white wood table'\",\n",
       " \"u'magic yoga'\",\n",
       " \"u'hand sanitizer'\",\n",
       " \"u'shovel digging in dirt'\",\n",
       " \"u'empty room'\",\n",
       " \"u'laptop icon'\",\n",
       " \"u'barbecue'\",\n",
       " \"u'moon isolated'\",\n",
       " \"u'pytajnik icon'\",\n",
       " \"u'pain'\",\n",
       " \"u'bible'\",\n",
       " \"u'\\\\u4e2d\\\\u5e74 \\\\u5973\\\\u6027 \\\\u65e5\\\\u672c\\\\u4eba'\",\n",
       " \"u'CZERPANIE PAPIERU'\",\n",
       " \"u'happy easter'\",\n",
       " \"u'brettljause'\",\n",
       " \"u'FEUX DARTIFICES'\",\n",
       " \"u'poisson rouge'\",\n",
       " \"u'confetti vector'\",\n",
       " \"u'server room'\",\n",
       " \"u'safe box'\",\n",
       " \"u'\\\\u62b9\\\\u8336'\",\n",
       " \"u'\\\\u82b1\\\\u3000\\\\u79cb'\",\n",
       " \"u'winter set'\",\n",
       " \"u'SHOPPING BAG'\",\n",
       " \"u'product'\",\n",
       " \"u'recycled paper bag mockup'\",\n",
       " \"u'mise \\\\xe0 jour'\",\n",
       " \"u'click for more info'\",\n",
       " \"u'home improvement'\",\n",
       " \"u'laptop screen home'\",\n",
       " \"u'shield'\",\n",
       " \"u'woman notary'\",\n",
       " \"u'decorative corner borders'\",\n",
       " \"u'arrested'\",\n",
       " \"u'de pollo'\",\n",
       " \"u'sprinting'\",\n",
       " \"u'\\\\u9b5a'\",\n",
       " \"u'ulotki reklamowe'\",\n",
       " \"u'icon entertainment'\",\n",
       " \"u'software icono'\",\n",
       " \"u'repair and maintenance icons'\",\n",
       " \"u'semaforo'\",\n",
       " \"u'trick or treat'\",\n",
       " \"u'grieta pared'\",\n",
       " \"u'global'\",\n",
       " \"u'gato barriga'\",\n",
       " \"u'brown plank'\",\n",
       " \"u'furniture template'\",\n",
       " \"u'lys blanc'\",\n",
       " \"u'wooden background'\",\n",
       " \"u'envelopes'\",\n",
       " \"u'colouring page'\",\n",
       " \"u'invitation food'\",\n",
       " \"u'casa'\",\n",
       " \"u'corona'\",\n",
       " \"u'grey watercolor'\",\n",
       " \"u'tokyo'\",\n",
       " \"u'mundo'\",\n",
       " \"u'highway sign'\",\n",
       " \"u'online courses'\",\n",
       " \"u'mango'\",\n",
       " \"u'white abstract'\",\n",
       " \"u'incendie securite'\",\n",
       " \"u'estepona'\",\n",
       " \"u'afval veiligheid'\",\n",
       " \"u'invitation party'\",\n",
       " \"u'puppy'\",\n",
       " \"u'plaquettes'\",\n",
       " \"u'business card mock up'\",\n",
       " \"u'wood logs'\",\n",
       " \"u'run logo'\",\n",
       " \"u'environment'\",\n",
       " \"u'outside ad park'\",\n",
       " \"u'persone computer disperate'\",\n",
       " \"u'\\\\u30b2\\\\u30fc\\\\u30e0'\",\n",
       " \"u'vintage vespa'\",\n",
       " \"u'kid autumn'\",\n",
       " \"u'cats and dogs'\",\n",
       " \"u'iPhone\\\\u3000\\\\u5145\\\\u96fb'\",\n",
       " \"u'rice field hand'\",\n",
       " \"u'wiese himmel'\",\n",
       " \"u'texas flag background'\",\n",
       " \"u'nightclub party'\",\n",
       " \"u'office interior'\",\n",
       " \"u'tokyo'\",\n",
       " \"u'mac mockup'\",\n",
       " \"u'carpeta'\",\n",
       " \"u'rotterdam haven'\",\n",
       " \"u'method of operations'\",\n",
       " \"u'child at hospital parents'\",\n",
       " \"u'geschenkgutschein hotel'\",\n",
       " \"u'pie chart'\",\n",
       " \"u'weird'\",\n",
       " \"u'EMERGENCY LIGHTS'\",\n",
       " \"u'collagene skin'\",\n",
       " \"u'shopping'\",\n",
       " \"u'new icon'\",\n",
       " \"u'PC arbeiten frau freizeit'\",\n",
       " \"u'texturas'\",\n",
       " \"u'paper old'\",\n",
       " \"u'food drive'\",\n",
       " \"u'pot plant'\",\n",
       " \"u'marketing automation'\",\n",
       " \"u'korken'\",\n",
       " \"u'girly'\",\n",
       " \"u'relax home'\",\n",
       " \"u'Learning Objectives'\",\n",
       " \"u'vulnerability management'\",\n",
       " \"u'hawaii'\",\n",
       " \"u'simbolo blanco telefono'\",\n",
       " \"u'sparks white'\",\n",
       " \"u'shrimp'\",\n",
       " \"u'halloween'\",\n",
       " \"u'selfie'\",\n",
       " \"u'fond sable mer'\",\n",
       " \"u'legal'\",\n",
       " \"u'people working'\",\n",
       " \"u'corn combine dust'\",\n",
       " \"u'adp'\",\n",
       " \"u'business man isolated'\",\n",
       " \"u'christmas'\",\n",
       " \"u'diamond no background'\",\n",
       " \"u'psychologist'\",\n",
       " \"u'icon zeugnis'\",\n",
       " \"u'5 targets'\",\n",
       " \"u'cardboard packages'\",\n",
       " \"u'Speech bubble'\",\n",
       " \"u'Pantoffel'\",\n",
       " \"u'christianity'\",\n",
       " \"u'balkonparty'\",\n",
       " \"u'Donut'\",\n",
       " \"u'working from home'\",\n",
       " \"u'BONFIRE NIGHT'\",\n",
       " \"u'medical'\",\n",
       " \"u'world mind'\",\n",
       " \"u'contrat'\",\n",
       " \"u'wood cross section'\",\n",
       " \"u'EKG'\",\n",
       " \"u'egypt 3d'\",\n",
       " \"u'dementia'\",\n",
       " \"u'allestimento natale tavolo'\",\n",
       " \"u'eid party'\",\n",
       " \"u'wine beer'\",\n",
       " \"u'organic food'\",\n",
       " \"u'sausages'\",\n",
       " \"u'obrero despido'\",\n",
       " \"u'watercolor shape vector'\",\n",
       " \"u'4th of july'\",\n",
       " \"u'maggiordomo'\",\n",
       " \"u'yellow thumbs up'\",\n",
       " \"u'laptop woman'\",\n",
       " \"u'persian carpet'\",\n",
       " \"u'mechanic opening box'\",\n",
       " \"u'chocolate slice'\",\n",
       " \"u'washington dc'\",\n",
       " \"u'\\\\u80cc\\\\u666f\\\\u3000\\\\u4e09\\\\u89d2\\\\u5f62'\",\n",
       " \"u'journey desert'\",\n",
       " \"u'gift icon'\",\n",
       " \"u'prayer'\",\n",
       " \"u'cocktails and cookies'\",\n",
       " \"u'home in hands'\",\n",
       " \"u'old man laptop'\",\n",
       " \"u'rosh hashanah shofar'\",\n",
       " \"u'it'\",\n",
       " \"u'middle age womans face'\",\n",
       " \"u'sun'\",\n",
       " \"u'beef skirt steak'\",\n",
       " \"u'Lips'\",\n",
       " \"u'envelope'\",\n",
       " \"u'paris'\",\n",
       " \"u'icons dairy free'\",\n",
       " \"u'Listen employees'\",\n",
       " \"u'temperature'\",\n",
       " \"u'\\\\u5973\\\\u6027'\",\n",
       " \"u'human resources'\",\n",
       " \"u'\\\\u5e7c\\\\u7a1a\\\\u5712'\",\n",
       " \"u'diccionario'\",\n",
       " \"u'\\\\u925b\\\\u7b46\\\\u3000\\\\u30a2\\\\u30a4\\\\u30b3\\\\u30f3'\",\n",
       " \"u'fathers day'\",\n",
       " \"u'gratulation Pr\\\\xfcfung'\",\n",
       " \"u'trockene haut'\",\n",
       " \"u'campamento'\",\n",
       " \"u'palm tree'\",\n",
       " \"u'weather icons'\",\n",
       " \"u'stra\\\\xdfenschild'\",\n",
       " \"u'apocalypse'\",\n",
       " \"u'viking'\",\n",
       " \"u'time management'\",\n",
       " \"u'photography logo'\",\n",
       " \"u'leg wax'\",\n",
       " \"u'Megaphon'\",\n",
       " \"u'voiture isol\\\\xe9'\",\n",
       " \"u'stone'\",\n",
       " \"u'cheese factory'\",\n",
       " \"u'samochod zima'\",\n",
       " \"u'ranch home'\",\n",
       " \"u'Doughnuts overhead'\",\n",
       " \"u'brooklyn'\",\n",
       " \"u'makeup model'\",\n",
       " \"u'light modern background'\",\n",
       " \"u'nude'\",\n",
       " \"u'socks pattern'\",\n",
       " \"u'web development'\",\n",
       " \"u'crossroads'\",\n",
       " \"u'voice mail'\",\n",
       " \"u'interview studio'\",\n",
       " \"u'arrow'\",\n",
       " \"u'cad drawing'\",\n",
       " \"u'Board of Directors'\",\n",
       " \"u'victorian pattern'\",\n",
       " \"u'plant growing'\",\n",
       " \"u'model man behind'\",\n",
       " \"u'cooking white background'\"]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_batch = []   # I think the model is overfitted, as it return very similar encoding\n",
    "for batch , img in enumerate(sample_pos_img_dataset):\n",
    "    p_batch.append(image_model(img))\n",
    "\n",
    "n_batch = []\n",
    "for batch , img in enumerate(sample_neg_img_dataset):\n",
    "    n_batch.append(image_model(img))\n",
    "\n",
    "q_batch = [] \n",
    "for batch , q in enumerate(sample_query_dataset):\n",
    "    if batch == 0 :\n",
    "        q_batch.append(text_model(q))\n",
    "        break\n",
    "\n",
    "anchor_query_seq = list(itemgetter(* list_of_indices)(q_test))[0]\n",
    "encoded_anchor = text_model(q)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def query_visualization_batches(query, q_test, p_test, n_test, pb_test):\n",
    "    \n",
    "    list_of_indices = np.flatnonzero(df['query']== query)\n",
    "    print(\"in test set with size {}, there are {} number of queries with text {}\".format(len(df), len(list_of_indices), query ))\n",
    "    \n",
    "    q_ = list(itemgetter(* list_of_indices)(q_test)) #get query test associated with this query\n",
    "    p_ = list(itemgetter(* list_of_indices)(p_test))\n",
    "    n_ = list(itemgetter(* list_of_indices)(n_test))\n",
    "    pb_ = list(itemgetter(* list_of_indices)(pb_test))\n",
    "    query_size = len(list_of_indices)\n",
    "    #print(len(q_), len(p_), len(n_), len(pb_))\n",
    "\n",
    "    # positive and negative inceptionV3 image datasets\n",
    "    vis_batch = 1\n",
    "    sample_pos_img_dataset = tf.data.Dataset.from_tensor_slices(p_)\n",
    "    sample_pos_img_dataset = sample_pos_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(vis_batch)\n",
    "\n",
    "    sample_neg_img_dataset = tf.data.Dataset.from_tensor_slices(n_)\n",
    "    sample_neg_img_dataset = sample_neg_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(vis_batch)\n",
    "\n",
    "    sample_position_bias_dataset = tf.data.Dataset.from_generator(lambda: gen_series(pb_), output_types=(tf.float32),output_shapes = ( ())) # if set it (1,) -> ValueError: `generator` yielded an element of shape () where an element of shape (1,) was expected\n",
    "    sample_position_bias_dataset = sample_position_bias_dataset.batch(vis_batch)\n",
    "\n",
    "    sample_query_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_series(q_), \n",
    "        output_types=(tf.int32), \n",
    "        output_shapes=( ( MAX_SENT_LENGTH)))\n",
    "    sample_query_dataset = sample_query_dataset.batch(vis_batch)\n",
    "\n",
    "    sample_query_dataset, sample_neg_img_dataset, sample_pos_img_dataset\n",
    "\n",
    "    p_batch = []   # I think the model is overfitted, as it return very similar encoding\n",
    "    for batch , img in enumerate(sample_pos_img_dataset):\n",
    "        p_batch.append(image_model(img))\n",
    "\n",
    "    n_batch = []\n",
    "    for batch , img in enumerate(sample_neg_img_dataset):\n",
    "        n_batch.append(image_model(img))\n",
    "\n",
    "    q_batch = [] \n",
    "    for batch , q in enumerate(sample_query_dataset):\n",
    "        q_batch.append(text_model(q))\n",
    "    #############\n",
    "    anchor_query_seq = list(itemgetter(* list_of_indices)(q_test))[0]\n",
    "    encoded_anchor = text_model(q)\n",
    "    ##############\n",
    "    return q_, p_, n_, q_batch, p_batch, n_batch, encoded_anchor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def precision_ranking_score_euc_distance(encoded_anchor, p_batch, n_batch):\n",
    "    psq_dist = []\n",
    "    nsq_dist = []\n",
    "    for batch , encoded_sample in enumerate(p_batch):\n",
    "        pos_dot = tf.linalg.diag_part(tf.tensordot(encoded_anchor, tf.transpose(encoded_sample),1))\n",
    "  \n",
    "        sq_pos_dist = tf.math.sqrt(tf.math.square(tf.norm(encoded_anchor,axis= 1 )) + tf.math.square(tf.norm(encoded_sample,axis= 1 )) - 2*pos_dot)\n",
    "\n",
    "        psq_dist.append(np.absolute(float(sq_pos_dist)))\n",
    "    \n",
    "    for batch , encoded_sample in enumerate(n_batch):  \n",
    "        neg_dot = tf.linalg.diag_part(tf.tensordot(encoded_anchor, tf.transpose(encoded_sample),1))\n",
    "    \n",
    "        sq_neg_dist = tf.math.sqrt(tf.math.square(tf.norm(encoded_anchor, axis= 1 )) + tf.math.square(tf.norm(encoded_sample,axis= 1 )) - 2*neg_dot)\n",
    "\n",
    "        nsq_dist.append(np.absolute(float(sq_neg_dist)))\n",
    "    \n",
    "    return psq_dist,nsq_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def compute_precision_dist(p_rank, psq_dist,nsq_dist) :\n",
    "    sorted_pos_ind = np.argsort(psq_dist)#[::-1][:len(pos_dot)] #sort ascending for euc dis\n",
    "    #print(sorted_pos_ind)\n",
    "    sorted_neg_ind = np.argsort(nsq_dist)#[::-1][:len(neg_dot)] \n",
    "    #print(sorted_neg_ind)\n",
    "    \n",
    "    j = k = 0\n",
    "    precision = 0\n",
    "    ranking_list = []\n",
    "    for i in range(p_rank):\n",
    "        \n",
    "        if psq_dist[sorted_pos_ind[j]] < nsq_dist[sorted_neg_ind[k]]: # lower distance means better\n",
    "            #print('p', 'index: {} dot value {}'.format(j, psq_dist[sorted_pos_ind[j]]))\n",
    "            ranking_list.append(('p' ,j, p_[j]))\n",
    "            precision+=1\n",
    "            j+=1\n",
    "        else:\n",
    "            #print('n', 'index: {} dot value {}'.format (k, nsq_dist[sorted_neg_ind[k]]))\n",
    "            ranking_list.append(('n' ,k, n_[k]))\n",
    "            k+=1\n",
    "    print('@{} precision for query {} based on Euclidean Distance of images : '.format(p_rank , query), precision/p_rank)\n",
    "    return ranking_list, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def visualize_images(path_list, n_to_vis, ranking_labels = []):\n",
    "    from PIL import Image, ImageOps\n",
    "\n",
    "    #n_to_vis = len(path_list)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for path_images in path_list:\n",
    "        for i in range(np.min([len(path_list), n_to_vis+1])):\n",
    "            ax = plt.subplot(8, 7, i + 1)\n",
    "            img1 = tf.image.decode_jpeg(tf.io.read_file(path_list[i]), channels=3)\n",
    "            img1 = tf.image.resize(img1, (240, 240))\n",
    "            plt.imshow(img1.numpy().astype(\"uint8\"))\n",
    "            if ranking_labels!=[]:\n",
    "                plt.title(ranking_labels[i])\n",
    "            plt.axis(\"off\")         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@2 precision for query poster based on Euclidean Distance of images :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#q_, p_, n_, q_batch, p_batch, n_batch, encoded_anchor = query_visualization_batches(query)\n",
    "psq_dist, nsq_dist = precision_ranking_score_euc_distance(encoded_anchor, p_batch, n_batch)\n",
    "ranking_list, precision = compute_precision_dist(2, psq_dist,nsq_dist)\n",
    "visualize_images(p_,2)\n",
    "visualize_images(n_,2)\n",
    "\n",
    "\n",
    "\n",
    "ranked_img_path = [ranking_list[i][2] for i in range(len(ranking_list))]\n",
    "ranking_labels = [ranking_list[i][0] for i in range(len(ranking_list))]\n",
    "\n",
    "visualize_images(ranked_img_path,2, ranking_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@5 precision for query social media based on Euclidean Distance of images :  0.6\n",
      "@10 precision for query social media based on Euclidean Distance of images :  0.8\n",
      "@15 precision for query social media based on Euclidean Distance of images :  0.8\n",
      "@20 precision for query social media based on Euclidean Distance of images :  0.85\n",
      "@25 precision for query social media based on Euclidean Distance of images :  0.88\n"
     ]
    }
   ],
   "source": [
    "ranking_list, precision = compute_precision_dist(5, psq_dist,nsq_dist)\n",
    "ranking_list, precision = compute_precision_dist(10, psq_dist,nsq_dist)\n",
    "ranking_list, precision = compute_precision_dist(15, psq_dist,nsq_dist)\n",
    "ranking_list, precision = compute_precision_dist(20, psq_dist,nsq_dist)\n",
    "ranking_list, precision = compute_precision_dist(25, psq_dist,nsq_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': 0, '10': 0, '15': 0, '20': 0, '25': 0, '30': 0}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rank = 20 # number of quries to visualize\n",
    "\n",
    "queries = freq_count.index[0:n_rank]\n",
    "precisions = {'5': 0 , '10': 0 , '15':0, '20':0, '25':0}\n",
    "\n",
    "for ind, query in enumerate(queries):\n",
    "    print('\\nquery = ', query)\n",
    "    list_of_indices = np.flatnonzero(df['query']== query)\n",
    "    print(\"in test set with size {}, there are {} number of queries with text {}\".format(len(df), len(list_of_indices), query ))\n",
    "\n",
    "    q_ = list(itemgetter(* list_of_indices)(q_test)) #get query test associated with this query\n",
    "    p_ = list(itemgetter(* list_of_indices)(p_test))\n",
    "    n_ = list(itemgetter(* list_of_indices)(n_test))\n",
    "    pb_ = list(itemgetter(* list_of_indices)(pb_test))\n",
    "    query_size = len(list_of_indices)\n",
    "\n",
    "    vis_batch = 1\n",
    "    sample_pos_img_dataset = tf.data.Dataset.from_tensor_slices(p_)\n",
    "    sample_pos_img_dataset = sample_pos_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(vis_batch)\n",
    "\n",
    "    sample_neg_img_dataset = tf.data.Dataset.from_tensor_slices(n_)\n",
    "    sample_neg_img_dataset = sample_neg_img_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(vis_batch)\n",
    "\n",
    "    sample_position_bias_dataset = tf.data.Dataset.from_generator(lambda: gen_series(pb_), output_types=(tf.float32),output_shapes = ( ())) # if set it (1,) -> ValueError: `generator` yielded an element of shape () where an element of shape (1,) was expected\n",
    "    sample_position_bias_dataset = sample_position_bias_dataset.batch(vis_batch)\n",
    "\n",
    "    sample_query_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_series(q_), \n",
    "        output_types=(tf.int32), \n",
    "        output_shapes=( ( MAX_SENT_LENGTH)))\n",
    "    sample_query_dataset = sample_query_dataset.batch(vis_batch)\n",
    "\n",
    "    sample_query_dataset, sample_neg_img_dataset, sample_pos_img_dataset\n",
    "\n",
    "    p_batch = []   # I think the model is overfitted, as it return very similar encoding\n",
    "    for batch , img in enumerate(sample_pos_img_dataset):\n",
    "        p_batch.append(image_model(img))\n",
    "\n",
    "    n_batch = []\n",
    "    for batch , img in enumerate(sample_neg_img_dataset):\n",
    "        n_batch.append(image_model(img))\n",
    "\n",
    "    q_batch = [] \n",
    "    for batch , q in enumerate(sample_query_dataset):\n",
    "        q_batch.append(text_model(q))\n",
    "\n",
    "    anchor_query_seq = list(itemgetter(* list_of_indices)(q_test))[0]\n",
    "    encoded_anchor = text_model(q)\n",
    "\n",
    "    for ranks in [5,10,15,20,25]: # get precisions for @5, @10, @15 , ... \n",
    "        print('\\nPrecisions @', ranks)\n",
    "\n",
    "        #q_, p_, n_, q_batch, p_batch, n_batch, encoded_anchor = query_visualization_batches(query)\n",
    "        psq_dist, nsq_dist = precision_ranking_score_euc_distance(encoded_anchor, p_batch, n_batch)\n",
    "        ranking_list, precision = compute_precision_dist(ranks, psq_dist,nsq_dist)\n",
    "        precisions[str(ranks)] += precision\n",
    "        #ranked_img_path = [ranking_list[i][2] for i in range(len(ranking_list))]\n",
    "        #ranking_labels = [ranking_list[i][0] for i in range(len(ranking_list))]\n",
    "        #visualize_images(ranked_img_path,27, ranking_labels)\n",
    "        \n",
    "    precisions[str(ranks)] = precisions[str(ranks)]/len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOT Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision (based on dot product: Ai > Ai+1) # anchor dot product to images are sorted descendingly\n",
    "def precision_ranking_score(encoded_anchor, p_batch, n_batch):\n",
    "    pos_dot = []\n",
    "    neg_dot = []\n",
    "    for batch , encoded_positive in enumerate(p_batch):\n",
    "        pos_dot.append(float(tf.tensordot(encoded_anchor, tf.transpose(encoded_positive),1)[0]))\n",
    "        \n",
    "    for batch , encoded_negative in enumerate(n_batch):  \n",
    "        neg_dot.append(float(tf.tensordot(encoded_anchor, tf.transpose(encoded_negative),1)[0]))\n",
    "    return pos_dot,neg_dot\n",
    "\n",
    "def compute_precision_dot(p_rank, pos_dot,neg_dot) :\n",
    "    sorted_pos_ind = np.argsort(pos_dot)[::-1][:len(pos_dot)] #sort descending for dot product\n",
    "    sorted_neg_ind = np.argsort(neg_dot)[::-1][:len(neg_dot)] \n",
    "\n",
    "    j = k = 0\n",
    "    precision = 0\n",
    "    ranking_list = []\n",
    "    for i in range(p_rank):\n",
    "        if pos_dot[sorted_pos_ind[j]] > neg_dot[sorted_neg_ind[k]]:\n",
    "            print('p', 'index: {} dot value {}'.format(j, pos_dot[sorted_pos_ind[j]]))\n",
    "            ranking_list.append(('p' ,j, p_[j]))\n",
    "            precision+=1\n",
    "            j+=1\n",
    "        else:\n",
    "            print('n', 'index: {} dot value {}'.format (k, neg_dot[sorted_neg_ind[k]]))\n",
    "            ranking_list.append(('n' ,k, n_[k]))\n",
    "            k+=1\n",
    "    print('@{} precision for query {} based on dot product of images : '.format(p_rank , query), precision/p_rank)\n",
    "    return ranking_list, precision\n",
    "\n",
    "pos_dot,neg_dot = precision_ranking_score( encoded_anchor, p_batch, n_batch)\n",
    "ranking_list, precision = compute_precision_dot(49, pos_dot,neg_dot)\n",
    "\n",
    "### VISUALIZE rankings based on dot product\n",
    "ranked_img_path = [ranking_list[i][2] for i in range(len(ranking_list))]\n",
    "\n",
    "visualize_images(ranked_img_path,49)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking based on Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision (based on dot product: Ai > Ai+1) # anchor dot product to images are sorted ascendingly\n",
    "def precision_ranking_score_euc_distance(query, query_seqs, p_img_paths,n_img_paths, position_bias, n_train):\n",
    "    \n",
    "    # calculate euclidean distance ( or cosine similarity score) here dot product first\n",
    "    anchor_vector = p_batch[0][0].numpy()\n",
    "    # normalize vector\n",
    "    encoded_anchor = tf.math.l2_normalize(anchor_vector, axis=None, epsilon=1e-12, name=None)\n",
    "    \n",
    "    ## calculate dot (or distance) between the query and pos and neg image encodings (within test set and )\n",
    "    psq_dist = []\n",
    "    nsq_dist = []\n",
    "\n",
    "    for batch , sample in enumerate(p_batch):\n",
    "        #sample = tf.math.l2_normalize(sample, axis=None, epsilon=1e-12, name=None)\n",
    "        pos_dot = float(tf.tensordot(encoded_anchor, tf.transpose(sample),1)[0])\n",
    "        psq_dist.append(np.absolute(float(tf.math.square(tf.norm(encoded_anchor)) + tf.math.square(tf.norm(sample)) - 2*pos_dot)))\n",
    "    \n",
    "    for batch , sample in enumerate(n_batch):  \n",
    "        #sample = tf.math.l2_normalize(sample, axis=None, epsilon=1e-12, name=None)\n",
    "        neg_dot = float(tf.tensordot(encoded_anchor, tf.transpose(sample),1)[0])\n",
    "        nsq_dist.append(np.absolute(float(tf.math.square(tf.norm(encoded_anchor)) + tf.math.square(tf.norm(sample)) - 2*neg_dot)))\n",
    "    \n",
    "    return psq_dist,nsq_dist, p_, n_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_dist(p_rank, psq_dist,nsq_dist) :\n",
    "    sorted_pos_ind = np.argsort(psq_dist)#[::-1][:len(pos_dot)] #sort ascending for euc dis\n",
    "    print(sorted_pos_ind)\n",
    "    sorted_neg_ind = np.argsort(nsq_dist)#[::-1][:len(neg_dot)] \n",
    "    print(sorted_neg_ind)\n",
    "    \n",
    "    j = k = 0\n",
    "    precision = 0\n",
    "    ranking_list = []\n",
    "    for i in range(p_rank):\n",
    "        \n",
    "        if psq_dist[sorted_pos_ind[j]] < nsq_dist[sorted_neg_ind[k]]: # lower distance means better\n",
    "            print('p', 'index: {} dot value {}'.format(j, psq_dist[sorted_pos_ind[j]]))\n",
    "            ranking_list.append(('p' ,j, p_[j]))\n",
    "            precision+=1\n",
    "            j+=1\n",
    "        else:\n",
    "            print('n', 'index: {} dot value {}'.format (k, nsq_dist[sorted_neg_ind[k]]))\n",
    "            ranking_list.append(('n' ,k, n_[k]))\n",
    "            k+=1\n",
    "    print('@{} precision for query {} based on Euclidean Distance of images : '.format(p_rank , query), precision/p_rank)\n",
    "    return ranking_list, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_ranking_score_euc_distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-4d7a907951ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'happy holidays'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpsq_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsq_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_ranking_score_euc_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_img_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_img_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mranking_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_precision_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsq_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsq_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mranked_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mranking_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranking_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_ranking_score_euc_distance' is not defined"
     ]
    }
   ],
   "source": [
    "query = 'happy holidays'\n",
    "psq_dist, nsq_dist, p_, n_ = precision_ranking_score_euc_distance(query, query_seqs, p_img_paths,n_img_paths, position_bias, n_train)\n",
    "ranking_list, precision = compute_precision_dist(19, psq_dist,nsq_dist)\n",
    "print( precision)\n",
    "ranked_img_path = [ranking_list[i][2] for i in range(len(ranking_list))]\n",
    "visualize_image_ranks(ranked_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "image_captioning.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
